{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5Ds1ZM41KC9"
   },
   "source": [
    "## Introduction: TAPAS\n",
    "\n",
    "* Original TAPAS paper (ACL 2020): https://www.aclweb.org/anthology/2020.acl-main.398/\n",
    "* Follow-up paper on intermediate pre-training (EMMNLP Findings 2020): https://www.aclweb.org/anthology/2020.findings-emnlp.27/\n",
    "* Original Github repository: https://github.com/google-research/tapas\n",
    "* Blog post: https://ai.googleblog.com/2020/04/using-neural-networks-to-find-answers.html\n",
    "\n",
    "TAPAS is an algorithm that (among other tasks) can answer questions about tabular data. It is essentially a BERT model with relative position embeddings and additional token type ids that encode tabular structure, and 2 classification heads on top: one for **cell selection** and one for (optionally) performing an **aggregation** among selected cells (such as summing or counting).\n",
    "\n",
    "Similar to BERT, the base `TapasModel` is pre-trained using the masked language modeling (MLM) objective on a large collection of tables from Wikipedia and associated texts. In addition, the authors further pre-trained the model on an second task (table entailment) to increase the numerical reasoning capabilities of TAPAS (as explained in the follow-up paper), which further improves performance on downstream tasks. \n",
    "\n",
    "In this notebook, we are going to fine-tune `TapasForQuestionAnswering` on [Sequential Question Answering (SQA)](https://www.microsoft.com/en-us/research/publication/search-based-neural-structured-learning-sequential-question-answering/), a dataset built by Microsoft Research which deals with asking questions related to a table in a **conversational set-up**. We are going to do so as in the original paper, by adding a randomly initialized cell selection head on top of the pre-trained base model (note that SQA does not have questions that involve aggregation and hence no aggregation head), and then fine-tuning them altogether.\n",
    "\n",
    "First, we install both the Transformers library as well as the dependency on [`torch-scatter`](https://github.com/rusty1s/pytorch_scatter), which the model requires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MUMrt5Ow_PEA",
    "outputId": "eda7d53e-9846-4941-ed72-ce84f495469f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "override r--r--r--  hannahcatri/staff for transformers/.git/objects/pack/pack-598f941cc1528133314cb220793d93512a7689d9.idx? ^C\n",
      "fatal: destination path 'transformers' already exists and is not an empty directory.\n",
      "\u001b[31mERROR: Directory './transformers' is not installable. Neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! rm -r transformers\n",
    "! git clone https://github.com/huggingface/transformers.git\n",
    "! cd transformers\n",
    "! pip install ./transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gx4u09iTyRjY",
    "outputId": "e4cd9f4b-7d8d-4b47-e8b2-304b921dba98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement torch-scatter==latest+cu101\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for torch-scatter==latest+cu101\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install torch-scatter==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.7.0.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BSZfmBt0meYm"
   },
   "source": [
    "We also install a small portion from the SQA training dataset, for demonstration purposes. This is a TSV file containing table-question pairs. Besides this, we also download the `table_csv` directory, which contains the actual tabular data.\n",
    "\n",
    "Note that you can download the entire SQA dataset on the [official website](https://www.microsoft.com/en-us/download/details.aspx?id=54253)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPrYJOn81f0D"
   },
   "source": [
    "## Prepare the data \n",
    "\n",
    "Let's look at the first few rows of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "2X27wyd805D8",
    "outputId": "7ccfd32c-e8dd-4fec-c044-d7d8de8dd578"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>annotator</th>\n",
       "      <th>position</th>\n",
       "      <th>question</th>\n",
       "      <th>table_file</th>\n",
       "      <th>answer_coordinates</th>\n",
       "      <th>answer_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sf-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>which incidents are in mission bay?</td>\n",
       "      <td>table_csv/2022_0117_locations.csv</td>\n",
       "      <td>['(0,0)', '(11,0)', '(37,0)', '(94,0)', '(283,...</td>\n",
       "      <td>['220170001', '220170053', '220170263', '22017...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sf-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>of those, which one has a Berry St address?</td>\n",
       "      <td>table_csv/2022_0117_locations.csv</td>\n",
       "      <td>[ '(283,0)']</td>\n",
       "      <td>[ '220172434' ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sf-3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>which are the incidents in station area 31?</td>\n",
       "      <td>table_csv/2022_0117_locations.csv</td>\n",
       "      <td>['(56,0)', '(114,0)', '(141,0)', '(170,0)', '(...</td>\n",
       "      <td>['220170355', '220170807', '220171052', '22017...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sf-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>of these, which neighbourhoods are they in?</td>\n",
       "      <td>table_csv/2022_0117_locations.csv</td>\n",
       "      <td>['(56,3)', '(114,3)', '(141,3)', '(170,3)', '(...</td>\n",
       "      <td>['Golden Gate Park', 'Inner Richmond', 'Inner ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sf-3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>and of those, which neighborhood has the highe...</td>\n",
       "      <td>table_csv/2022_0117_locations.csv</td>\n",
       "      <td>['(345,3)']</td>\n",
       "      <td>['Outer Richmond']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  annotator  position  \\\n",
       "0  sf-2          0         0   \n",
       "1  sf-2          0         1   \n",
       "2  sf-3          1         0   \n",
       "3  sf-3          1         1   \n",
       "4  sf-3          1         2   \n",
       "\n",
       "                                            question  \\\n",
       "0                which incidents are in mission bay?   \n",
       "1        of those, which one has a Berry St address?   \n",
       "2        which are the incidents in station area 31?   \n",
       "3        of these, which neighbourhoods are they in?   \n",
       "4  and of those, which neighborhood has the highe...   \n",
       "\n",
       "                          table_file  \\\n",
       "0  table_csv/2022_0117_locations.csv   \n",
       "1  table_csv/2022_0117_locations.csv   \n",
       "2  table_csv/2022_0117_locations.csv   \n",
       "3  table_csv/2022_0117_locations.csv   \n",
       "4  table_csv/2022_0117_locations.csv   \n",
       "\n",
       "                                  answer_coordinates  \\\n",
       "0  ['(0,0)', '(11,0)', '(37,0)', '(94,0)', '(283,...   \n",
       "1                                       [ '(283,0)']   \n",
       "2  ['(56,0)', '(114,0)', '(141,0)', '(170,0)', '(...   \n",
       "3  ['(56,3)', '(114,3)', '(141,3)', '(170,3)', '(...   \n",
       "4                                        ['(345,3)']   \n",
       "\n",
       "                                         answer_text  \n",
       "0  ['220170001', '220170053', '220170263', '22017...  \n",
       "1                                    [ '220172434' ]  \n",
       "2  ['220170355', '220170807', '220171052', '22017...  \n",
       "3  ['Golden Gate Park', 'Inner Richmond', 'Inner ...  \n",
       "4                                 ['Outer Richmond']  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_excel(\"sqa_train_set_sfcfs.xlsx\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OMJ4dNBV1oj6"
   },
   "source": [
    "As you can see, each row corresponds to a question related to a table. \n",
    "* The `position` column identifies whether the question is the first, second, ... in a sequence of questions related to a table. \n",
    "* The `table_file` column identifies the name of the table file, which refers to a CSV file in the `table_csv` directory.\n",
    "* The `answer_coordinates` and `answer_text` columns indicate the answer to the question. The `answer_coordinates` is a list of tuples, each tuple being a (row_index, column_index) pair. The `answer_text` column is a list of strings, indicating the cell values.\n",
    "\n",
    "However, the `answer_coordinates` and `answer_text` columns are currently not recognized as real Python lists of Python tuples and strings respectively. Let's do that first using the `.literal_eval()`function of the `ast` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 511
    },
    "id": "BAovAs5s1k10",
    "outputId": "0849a829-4ae8-43e9-e138-177fa14e3e36"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>annotator</th>\n",
       "      <th>position</th>\n",
       "      <th>question</th>\n",
       "      <th>table_file</th>\n",
       "      <th>answer_coordinates</th>\n",
       "      <th>answer_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sf-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>which incidents are in mission bay?</td>\n",
       "      <td>table_csv/2022_0117_locations.csv</td>\n",
       "      <td>[(0, 0), (11, 0), (37, 0), (94, 0), (283, 0)]</td>\n",
       "      <td>[220170001, 220170053, 220170263, 220170622, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sf-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>of those, which one has a Berry St address?</td>\n",
       "      <td>table_csv/2022_0117_locations.csv</td>\n",
       "      <td>[(283, 0)]</td>\n",
       "      <td>[220172434]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sf-3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>which are the incidents in station area 31?</td>\n",
       "      <td>table_csv/2022_0117_locations.csv</td>\n",
       "      <td>[(56, 0), (114, 0), (141, 0), (170, 0), (286, ...</td>\n",
       "      <td>[220170355, 220170807, 220171052, 220171247, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sf-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>of these, which neighbourhoods are they in?</td>\n",
       "      <td>table_csv/2022_0117_locations.csv</td>\n",
       "      <td>[(56, 3), (114, 3), (141, 3), (170, 3), (286, ...</td>\n",
       "      <td>[Golden Gate Park, Inner Richmond, Inner Richm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sf-3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>and of those, which neighborhood has the highe...</td>\n",
       "      <td>table_csv/2022_0117_locations.csv</td>\n",
       "      <td>[(345, 3)]</td>\n",
       "      <td>[Outer Richmond]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sf-4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>what is the address of incident 220170143?</td>\n",
       "      <td>table_csv/2022_0117_locations.csv</td>\n",
       "      <td>[(18, 1)]</td>\n",
       "      <td>[18TH ST/CASTRO ST]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  annotator  position  \\\n",
       "0  sf-2          0         0   \n",
       "1  sf-2          0         1   \n",
       "2  sf-3          1         0   \n",
       "3  sf-3          1         1   \n",
       "4  sf-3          1         2   \n",
       "5  sf-4          2         0   \n",
       "\n",
       "                                            question  \\\n",
       "0                which incidents are in mission bay?   \n",
       "1        of those, which one has a Berry St address?   \n",
       "2        which are the incidents in station area 31?   \n",
       "3        of these, which neighbourhoods are they in?   \n",
       "4  and of those, which neighborhood has the highe...   \n",
       "5         what is the address of incident 220170143?   \n",
       "\n",
       "                          table_file  \\\n",
       "0  table_csv/2022_0117_locations.csv   \n",
       "1  table_csv/2022_0117_locations.csv   \n",
       "2  table_csv/2022_0117_locations.csv   \n",
       "3  table_csv/2022_0117_locations.csv   \n",
       "4  table_csv/2022_0117_locations.csv   \n",
       "5  table_csv/2022_0117_locations.csv   \n",
       "\n",
       "                                  answer_coordinates  \\\n",
       "0      [(0, 0), (11, 0), (37, 0), (94, 0), (283, 0)]   \n",
       "1                                         [(283, 0)]   \n",
       "2  [(56, 0), (114, 0), (141, 0), (170, 0), (286, ...   \n",
       "3  [(56, 3), (114, 3), (141, 3), (170, 3), (286, ...   \n",
       "4                                         [(345, 3)]   \n",
       "5                                          [(18, 1)]   \n",
       "\n",
       "                                         answer_text  \n",
       "0  [220170001, 220170053, 220170263, 220170622, 2...  \n",
       "1                                        [220172434]  \n",
       "2  [220170355, 220170807, 220171052, 220171247, 2...  \n",
       "3  [Golden Gate Park, Inner Richmond, Inner Richm...  \n",
       "4                                   [Outer Richmond]  \n",
       "5                                [18TH ST/CASTRO ST]  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "def _parse_answer_coordinates(answer_coordinate_str):\n",
    "  \"\"\"Parses the answer_coordinates of a question.\n",
    "  Args:\n",
    "    answer_coordinate_str: A string representation of a Python list of tuple\n",
    "      strings.\n",
    "      For example: \"['(1, 4)','(1, 3)', ...]\"\n",
    "  \"\"\"\n",
    "\n",
    "  try:\n",
    "    answer_coordinates = []\n",
    "    # make a list of strings\n",
    "    coords = ast.literal_eval(answer_coordinate_str)\n",
    "    # parse each string as a tuple\n",
    "    for row_index, column_index in sorted(\n",
    "        ast.literal_eval(coord) for coord in coords):\n",
    "      answer_coordinates.append((row_index, column_index))\n",
    "  except SyntaxError:\n",
    "    raise ValueError('Unable to evaluate %s' % answer_coordinate_str)\n",
    "  \n",
    "  return answer_coordinates\n",
    "\n",
    "\n",
    "def _parse_answer_text(answer_text):\n",
    "  \"\"\"Populates the answer_texts field of `answer` by parsing `answer_text`.\n",
    "  Args:\n",
    "    answer_text: A string representation of a Python list of strings.\n",
    "      For example: \"[u'test', u'hello', ...]\"\n",
    "    answer: an Answer object.\n",
    "  \"\"\"\n",
    "  try:\n",
    "    answer = []\n",
    "    for value in ast.literal_eval(answer_text):\n",
    "      answer.append(value)\n",
    "  except SyntaxError:\n",
    "    raise ValueError('Unable to evaluate %s' % answer_text)\n",
    "\n",
    "  return answer\n",
    "\n",
    "data['answer_coordinates'] = data['answer_coordinates'].apply(lambda coords_str: _parse_answer_coordinates(coords_str))\n",
    "data['answer_text'] = data['answer_text'].apply(lambda txt: _parse_answer_text(txt))\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7FYPpdW5dY4"
   },
   "source": [
    "Let's create a new dataframe that groups questions which are asked in a sequence related to the table. We can do this by adding a `sequence_id` column, which is a combination of the `id` and `annotator` columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "O1Quo0FL7h9-",
    "outputId": "5223d575-b86d-41e6-b23a-6071b3048211"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>annotator</th>\n",
       "      <th>position</th>\n",
       "      <th>question</th>\n",
       "      <th>table_file</th>\n",
       "      <th>answer_coordinates</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>sequence_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sf-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>which incidents are in mission bay?</td>\n",
       "      <td>table_csv/2022_0117_locations.csv</td>\n",
       "      <td>[(0, 0), (11, 0), (37, 0), (94, 0), (283, 0)]</td>\n",
       "      <td>[220170001, 220170053, 220170263, 220170622, 2...</td>\n",
       "      <td>sf-2-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sf-2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>of those, which one has a Berry St address?</td>\n",
       "      <td>table_csv/2022_0117_locations.csv</td>\n",
       "      <td>[(283, 0)]</td>\n",
       "      <td>[220172434]</td>\n",
       "      <td>sf-2-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sf-3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>which are the incidents in station area 31?</td>\n",
       "      <td>table_csv/2022_0117_locations.csv</td>\n",
       "      <td>[(56, 0), (114, 0), (141, 0), (170, 0), (286, ...</td>\n",
       "      <td>[220170355, 220170807, 220171052, 220171247, 2...</td>\n",
       "      <td>sf-3-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sf-3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>of these, which neighbourhoods are they in?</td>\n",
       "      <td>table_csv/2022_0117_locations.csv</td>\n",
       "      <td>[(56, 3), (114, 3), (141, 3), (170, 3), (286, ...</td>\n",
       "      <td>[Golden Gate Park, Inner Richmond, Inner Richm...</td>\n",
       "      <td>sf-3-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sf-3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>and of those, which neighborhood has the highe...</td>\n",
       "      <td>table_csv/2022_0117_locations.csv</td>\n",
       "      <td>[(345, 3)]</td>\n",
       "      <td>[Outer Richmond]</td>\n",
       "      <td>sf-3-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  annotator  position  \\\n",
       "0  sf-2          0         0   \n",
       "1  sf-2          0         1   \n",
       "2  sf-3          1         0   \n",
       "3  sf-3          1         1   \n",
       "4  sf-3          1         2   \n",
       "\n",
       "                                            question  \\\n",
       "0                which incidents are in mission bay?   \n",
       "1        of those, which one has a Berry St address?   \n",
       "2        which are the incidents in station area 31?   \n",
       "3        of these, which neighbourhoods are they in?   \n",
       "4  and of those, which neighborhood has the highe...   \n",
       "\n",
       "                          table_file  \\\n",
       "0  table_csv/2022_0117_locations.csv   \n",
       "1  table_csv/2022_0117_locations.csv   \n",
       "2  table_csv/2022_0117_locations.csv   \n",
       "3  table_csv/2022_0117_locations.csv   \n",
       "4  table_csv/2022_0117_locations.csv   \n",
       "\n",
       "                                  answer_coordinates  \\\n",
       "0      [(0, 0), (11, 0), (37, 0), (94, 0), (283, 0)]   \n",
       "1                                         [(283, 0)]   \n",
       "2  [(56, 0), (114, 0), (141, 0), (170, 0), (286, ...   \n",
       "3  [(56, 3), (114, 3), (141, 3), (170, 3), (286, ...   \n",
       "4                                         [(345, 3)]   \n",
       "\n",
       "                                         answer_text sequence_id  \n",
       "0  [220170001, 220170053, 220170263, 220170622, 2...      sf-2-0  \n",
       "1                                        [220172434]      sf-2-0  \n",
       "2  [220170355, 220170807, 220171052, 220171247, 2...      sf-3-1  \n",
       "3  [Golden Gate Park, Inner Richmond, Inner Richm...      sf-3-1  \n",
       "4                                   [Outer Richmond]      sf-3-1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sequence_id(example_id, annotator):\n",
    "  if \"-\" in str(annotator):\n",
    "    raise ValueError('\"-\" not allowed in annotator.')\n",
    "  return f\"{example_id}-{annotator}\"\n",
    "\n",
    "data['sequence_id'] = data.apply(lambda x: get_sequence_id(x.id, x.annotator), axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 541
    },
    "id": "-uPpds5D762B",
    "outputId": "38aa6f13-2cc7-4d96-b8b3-a510288bfca2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>table_file</th>\n",
       "      <th>answer_coordinates</th>\n",
       "      <th>answer_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequence_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sf-2-0</th>\n",
       "      <td>[which incidents are in mission bay?, of those...</td>\n",
       "      <td>table_csv/2022_0117_locations.csv</td>\n",
       "      <td>[[(0, 0), (11, 0), (37, 0), (94, 0), (283, 0)]...</td>\n",
       "      <td>[[220170001, 220170053, 220170263, 220170622, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sf-3-1</th>\n",
       "      <td>[which are the incidents in station area 31?, ...</td>\n",
       "      <td>table_csv/2022_0117_locations.csv</td>\n",
       "      <td>[[(56, 0), (114, 0), (141, 0), (170, 0), (286,...</td>\n",
       "      <td>[[220170355, 220170807, 220171052, 220171247, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sf-4-2</th>\n",
       "      <td>[what is the address of incident 220170143?]</td>\n",
       "      <td>table_csv/2022_0117_locations.csv</td>\n",
       "      <td>[[(18, 1)]]</td>\n",
       "      <td>[[18TH ST/CASTRO ST]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      question  \\\n",
       "sequence_id                                                      \n",
       "sf-2-0       [which incidents are in mission bay?, of those...   \n",
       "sf-3-1       [which are the incidents in station area 31?, ...   \n",
       "sf-4-2            [what is the address of incident 220170143?]   \n",
       "\n",
       "                                    table_file  \\\n",
       "sequence_id                                      \n",
       "sf-2-0       table_csv/2022_0117_locations.csv   \n",
       "sf-3-1       table_csv/2022_0117_locations.csv   \n",
       "sf-4-2       table_csv/2022_0117_locations.csv   \n",
       "\n",
       "                                            answer_coordinates  \\\n",
       "sequence_id                                                      \n",
       "sf-2-0       [[(0, 0), (11, 0), (37, 0), (94, 0), (283, 0)]...   \n",
       "sf-3-1       [[(56, 0), (114, 0), (141, 0), (170, 0), (286,...   \n",
       "sf-4-2                                             [[(18, 1)]]   \n",
       "\n",
       "                                                   answer_text  \n",
       "sequence_id                                                     \n",
       "sf-2-0       [[220170001, 220170053, 220170263, 220170622, ...  \n",
       "sf-3-1       [[220170355, 220170807, 220171052, 220171247, ...  \n",
       "sf-4-2                                   [[18TH ST/CASTRO ST]]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's group table-question pairs by sequence id, and remove some columns we don't need \n",
    "grouped = data.groupby(by='sequence_id').agg(lambda x: x.tolist())\n",
    "grouped = grouped.drop(columns=['id', 'annotator', 'position'])\n",
    "grouped['table_file'] = grouped['table_file'].apply(lambda x: x[0])\n",
    "grouped.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6RKTkSeLLyJ"
   },
   "source": [
    "Each row in the dataframe above now consists of a **table and one or more questions** which are asked in a **sequence**. Let's visualize the first row, i.e. a table, together with its queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 525
    },
    "id": "J-dTi5omLdN_",
    "outputId": "b8e1d893-8d8b-4540-dc35-57586312c992"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>call_number</th>\n",
       "      <th>address</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>station_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220170001</td>\n",
       "      <td>700 Block of 4TH ST</td>\n",
       "      <td>94107.0</td>\n",
       "      <td>Mission Bay</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220170004</td>\n",
       "      <td>1000 Block of POTRERO AVE</td>\n",
       "      <td>94110.0</td>\n",
       "      <td>Potrero Hill</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220170012</td>\n",
       "      <td>500 Block of GREEN ST</td>\n",
       "      <td>94133.0</td>\n",
       "      <td>North Beach</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220170017</td>\n",
       "      <td>1000 Block of MARKET ST</td>\n",
       "      <td>94102.0</td>\n",
       "      <td>Tenderloin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220170020</td>\n",
       "      <td>0 Block of BLK MOLIMO DR</td>\n",
       "      <td>94127.0</td>\n",
       "      <td>West of Twin Peaks</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>220173312</td>\n",
       "      <td>1200 Block of MARKET ST</td>\n",
       "      <td>94103.0</td>\n",
       "      <td>South of Market</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>220173322</td>\n",
       "      <td>100 Block of CASELLI AV</td>\n",
       "      <td>94114.0</td>\n",
       "      <td>Castro/Upper Market</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>220173329</td>\n",
       "      <td>700 Block of LA PLAYA</td>\n",
       "      <td>94121.0</td>\n",
       "      <td>Outer Richmond</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>220173330</td>\n",
       "      <td>WALLER ST/MASONIC AV</td>\n",
       "      <td>94117.0</td>\n",
       "      <td>Haight Ashbury</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>220173335</td>\n",
       "      <td>400 Block of ELLIS ST</td>\n",
       "      <td>94102.0</td>\n",
       "      <td>Tenderloin</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>389 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    call_number                    address  zipcode         neighborhood  \\\n",
       "0     220170001        700 Block of 4TH ST  94107.0          Mission Bay   \n",
       "1     220170004  1000 Block of POTRERO AVE  94110.0         Potrero Hill   \n",
       "2     220170012      500 Block of GREEN ST  94133.0          North Beach   \n",
       "3     220170017    1000 Block of MARKET ST  94102.0           Tenderloin   \n",
       "4     220170020   0 Block of BLK MOLIMO DR  94127.0   West of Twin Peaks   \n",
       "..          ...                        ...      ...                  ...   \n",
       "384   220173312    1200 Block of MARKET ST  94103.0      South of Market   \n",
       "385   220173322    100 Block of CASELLI AV  94114.0  Castro/Upper Market   \n",
       "386   220173329      700 Block of LA PLAYA  94121.0       Outer Richmond   \n",
       "387   220173330       WALLER ST/MASONIC AV  94117.0       Haight Ashbury   \n",
       "388   220173335      400 Block of ELLIS ST  94102.0           Tenderloin   \n",
       "\n",
       "    station_area  \n",
       "0              8  \n",
       "1             37  \n",
       "2             28  \n",
       "3              1  \n",
       "4             39  \n",
       "..           ...  \n",
       "384           36  \n",
       "385           24  \n",
       "386           34  \n",
       "387           21  \n",
       "388            3  \n",
       "\n",
       "[389 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['which incidents are in mission bay?', 'of those, which one has a Berry St address?']\n"
     ]
    }
   ],
   "source": [
    "# path to the directory containing all csv files\n",
    "table_csv_path = \"table_csv\"\n",
    "\n",
    "item = grouped.iloc[0]\n",
    "table = pd.read_csv(table_csv_path + item.table_file[9:]).astype(str) \n",
    "\n",
    "display(table)\n",
    "print(\"\")\n",
    "print(item.question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'220170001'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.iloc[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yw8MqIExLnnq"
   },
   "source": [
    "We can see that there are 3 sequential questions asked related to the contents of the table. \n",
    "\n",
    "We can now use `TapasTokenizer` to batch encode this, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "t5iU5byAICWb"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import TapasTokenizer\n",
    "\n",
    "# initialize the tokenizer\n",
    "tokenizer = TapasTokenizer.from_pretrained(\"google/tapas-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220170001\n",
      "220170053\n",
      "220170263\n",
      "220170622\n",
      "220172434\n",
      "220172434\n",
      "[['220170001', '220170053', '220170263', '220170622', '220172434'], ['220172434']]\n",
      "220170355\n",
      "220170807\n",
      "220171052\n",
      "220171247\n",
      "220172473\n",
      "220172577\n",
      "220172991\n",
      "Golden Gate Park\n",
      "Inner Richmond\n",
      "Inner Richmond\n",
      "Outer Richmond\n",
      "Inner Richmond\n",
      "Inner Richmond\n",
      "Outer Richmond\n",
      "Outer Richmond\n",
      "[['220170355', '220170807', '220171052', '220171247', '220172473', '220172577', '220172991'], ['Golden Gate Park', 'Inner Richmond', 'Inner Richmond', 'Outer Richmond', 'Inner Richmond', 'Inner Richmond', 'Outer Richmond'], ['Outer Richmond']]\n",
      "18TH ST/CASTRO ST\n",
      "[['18TH ST/CASTRO ST']]\n"
     ]
    }
   ],
   "source": [
    "for index, row in grouped.iterrows():\n",
    "    for x in row['answer_coordinates']:\n",
    "        for y in x:\n",
    "            #print(y)\n",
    "            #y=y.strip(\"()\")\n",
    "            print(table.iloc[y])\n",
    "    print(row['answer_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5qOBiUPEGgK8",
    "outputId": "7bc36d39-21be-433e-ecde-3f0d81c340ea"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Couldn't find all answers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b20f92da7b2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m encoding = tokenizer(table=table, queries=item.question, answer_coordinates=item.answer_coordinates, answer_text=item.answer_text,\n\u001b[0m\u001b[1;32m      9\u001b[0m                      truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n\u001b[1;32m     10\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/models/tapas/tokenization_tapas.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, table, queries, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_batched\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m             return self.batch_encode_plus(\n\u001b[0m\u001b[1;32m    604\u001b[0m                 \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m                 \u001b[0mqueries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/models/tapas/tokenization_tapas.py\u001b[0m in \u001b[0;36mbatch_encode_plus\u001b[0;34m(self, table, queries, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    719\u001b[0m             )\n\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         return self._batch_encode_plus(\n\u001b[0m\u001b[1;32m    722\u001b[0m             \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mqueries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/models/tapas/tokenization_tapas.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[0;34m(self, table, queries, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0mqueries_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m         batch_outputs = self._batch_prepare_for_model(\n\u001b[0m\u001b[1;32m    789\u001b[0m             \u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/models/tapas/tokenization_tapas.py\u001b[0m in \u001b[0;36m_batch_prepare_for_model\u001b[0;34m(self, raw_table, raw_queries, tokenized_table, queries_tokens, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, prepend_batch_axis, **kwargs)\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_queries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueries_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_coordinates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m             \u001b[0mraw_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_coords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_txt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m             outputs = self.prepare_for_model(\n\u001b[0m\u001b[1;32m    844\u001b[0m                 \u001b[0mraw_table\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0mraw_query\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/models/tapas/tokenization_tapas.py\u001b[0m in \u001b[0;36mprepare_for_model\u001b[0;34m(self, raw_table, raw_query, tokenized_table, query_tokens, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, prepend_batch_axis, **kwargs)\u001b[0m\n\u001b[1;32m   1199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0manswer_coordinates\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0manswer_text\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1201\u001b[0;31m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_answer_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_coordinates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1202\u001b[0m             \u001b[0mnumeric_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_numeric_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m             \u001b[0mnumeric_values_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_numeric_values_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/models/tapas/tokenization_tapas.py\u001b[0m in \u001b[0;36mget_answer_ids\u001b[0;34m(self, column_ids, row_ids, tokenized_table, answer_texts_question, answer_coordinates_question)\u001b[0m\n\u001b[1;32m   1776\u001b[0m                 \u001b[0manswer_texts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manswer_texts_question\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m             )\n\u001b[0;32m-> 1778\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_answer_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_coordinates_question\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m     def _pad(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/models/tapas/tokenization_tapas.py\u001b[0m in \u001b[0;36m_get_answer_ids\u001b[0;34m(self, column_ids, row_ids, answer_coordinates)\u001b[0m\n\u001b[1;32m   1765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmissing_count\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1767\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Couldn't find all answers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1768\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0manswer_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Couldn't find all answers"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import TapasTokenizer\n",
    "\n",
    "# initialize the tokenizer\n",
    "tokenizer = TapasTokenizer.from_pretrained(\"google/tapas-base\")\n",
    "\n",
    "\n",
    "encoding = tokenizer(table=table, queries=item.question, answer_coordinates=item.answer_coordinates, answer_text=item.answer_text,\n",
    "                     truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
    "encoding.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y2JRiKjPRHAF"
   },
   "source": [
    "TAPAS basically flattens every table-question pair before feeding it into a BERT like model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "id": "lhipz2_GRNKQ",
    "outputId": "a3ad3993-5173-45c7-a43b-993ab42f77e3"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b0e105b89d7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'encoding' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer.decode(encoding[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nVeB5IPaN5oN"
   },
   "source": [
    "The `token_type_ids` created here will be of shape (batch_size, sequence_length, 7), as TAPAS uses 7 different token types to encode tabular structure. Let's verify this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "zM0v-pwbN6gR"
   },
   "outputs": [],
   "source": [
    "assert encoding[\"token_type_ids\"].shape == (3, 512, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMt7cWJMLvue"
   },
   "source": [
    "\n",
    "\n",
    "One thing we can verify is whether the `prev_label` token type ids are created correctly. These indicate which tokens were (part of) an answer to the previous table-question pair. \n",
    "\n",
    "The prev_label token type ids of the first example in a batch must always be zero (since there's no previous table-question pair). Let's verify this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ytUk-H1yL9cc"
   },
   "outputs": [],
   "source": [
    "assert encoding[\"token_type_ids\"][0][:,3].sum() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJ_o-82nMfK5"
   },
   "source": [
    "However, the `prev_label` token type ids of the second table-question pair in the batch must be set to 1 for the tokens which were an answer to the previous (i.e. the first) table question pair in the batch. The answers to the first table-question pair are the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yxT9h2LIMNt3",
    "outputId": "69b29df5-8103-4b55-e8f4-598bd637a546"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tommy Green', 'Janis Dalins', 'Ugo Frigerio', 'Karl Hahnel', 'Ettore Rivolta', 'Paul Sievert', 'Henri Quintric', 'Ernie Crosbie', 'Bill Chisholm', 'Alfred Maasik', 'Henry Cieman', 'John Moralis', 'Francesco Pretti', 'Arthur Tell Schwab', 'Harry Hinkel']\n"
     ]
    }
   ],
   "source": [
    "print(item.answer_text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSUkMGAcMpfE"
   },
   "source": [
    "So let's now verify whether the `prev_label` ids of the second table-question pair are set correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uv6P7OpJGxuu",
    "outputId": "69b92a6a-408f-48f8-9842-dd3842f7188c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] 0\n",
      "where 0\n",
      "are 0\n",
      "they 0\n",
      "from 0\n",
      "? 0\n",
      "[SEP] 0\n",
      "rank 0\n",
      "name 0\n",
      "nationality 0\n",
      "time 0\n",
      "( 0\n",
      "hand 0\n",
      ") 0\n",
      "notes 0\n",
      "[EMPTY] 0\n",
      "tommy 1\n",
      "green 1\n",
      "great 0\n",
      "britain 0\n",
      "4 0\n",
      ": 0\n",
      "50 0\n",
      ": 0\n",
      "10 0\n",
      "or 0\n",
      "[EMPTY] 0\n",
      "jan 1\n",
      "##is 1\n",
      "dali 1\n",
      "##ns 1\n",
      "latvia 0\n",
      "4 0\n",
      ": 0\n",
      "57 0\n",
      ": 0\n",
      "20 0\n",
      "[EMPTY] 0\n",
      "[EMPTY] 0\n",
      "u 1\n",
      "##go 1\n",
      "fr 1\n",
      "##iger 1\n",
      "##io 1\n",
      "italy 0\n",
      "4 0\n",
      ": 0\n",
      "59 0\n",
      ": 0\n",
      "06 0\n",
      "[EMPTY] 0\n",
      "4 0\n",
      ". 0\n",
      "0 0\n",
      "karl 1\n",
      "hahn 1\n",
      "##el 1\n",
      "germany 0\n",
      "5 0\n",
      ": 0\n",
      "06 0\n",
      ": 0\n",
      "06 0\n",
      "[EMPTY] 0\n",
      "5 0\n",
      ". 0\n",
      "0 0\n",
      "et 1\n",
      "##tore 1\n",
      "ri 1\n",
      "##vo 1\n",
      "##lta 1\n",
      "italy 0\n",
      "5 0\n",
      ": 0\n",
      "07 0\n",
      ": 0\n",
      "39 0\n",
      "[EMPTY] 0\n",
      "6 0\n",
      ". 0\n",
      "0 0\n",
      "paul 1\n",
      "si 1\n",
      "##ever 1\n",
      "##t 1\n",
      "germany 0\n",
      "5 0\n",
      ": 0\n",
      "16 0\n",
      ": 0\n",
      "41 0\n",
      "[EMPTY] 0\n",
      "7 0\n",
      ". 0\n",
      "0 0\n",
      "henri 1\n",
      "qui 1\n",
      "##nt 1\n",
      "##ric 1\n",
      "france 0\n",
      "5 0\n",
      ": 0\n",
      "27 0\n",
      ": 0\n",
      "25 0\n",
      "[EMPTY] 0\n",
      "8 0\n",
      ". 0\n",
      "0 0\n",
      "ernie 1\n",
      "cr 1\n",
      "##os 1\n",
      "##bie 1\n",
      "united 0\n",
      "states 0\n",
      "5 0\n",
      ": 0\n",
      "28 0\n",
      ": 0\n",
      "02 0\n",
      "[EMPTY] 0\n",
      "9 0\n",
      ". 0\n",
      "0 0\n",
      "bill 1\n",
      "chi 1\n",
      "##sho 1\n",
      "##lm 1\n",
      "united 0\n",
      "states 0\n",
      "5 0\n",
      ": 0\n",
      "51 0\n",
      ": 0\n",
      "00 0\n",
      "[EMPTY] 0\n",
      "10 0\n",
      ". 0\n",
      "0 0\n",
      "alfred 1\n",
      "ma 1\n",
      "##asi 1\n",
      "##k 1\n",
      "estonia 0\n",
      "6 0\n",
      ": 0\n",
      "19 0\n",
      ": 0\n",
      "00 0\n",
      "[EMPTY] 0\n",
      "[EMPTY] 0\n",
      "henry 1\n",
      "ci 1\n",
      "##eman 1\n",
      "canada 0\n",
      "[EMPTY] 0\n",
      "d 0\n",
      "##n 0\n",
      "##f 0\n",
      "[EMPTY] 0\n",
      "john 1\n",
      "moral 1\n",
      "##is 1\n",
      "greece 0\n",
      "[EMPTY] 0\n",
      "d 0\n",
      "##n 0\n",
      "##f 0\n",
      "[EMPTY] 0\n",
      "francesco 1\n",
      "pre 1\n",
      "##tti 1\n",
      "italy 0\n",
      "[EMPTY] 0\n",
      "d 0\n",
      "##n 0\n",
      "##f 0\n",
      "[EMPTY] 0\n",
      "arthur 1\n",
      "tell 1\n",
      "sc 1\n",
      "##hwa 1\n",
      "##b 1\n",
      "switzerland 0\n",
      "[EMPTY] 0\n",
      "d 0\n",
      "##n 0\n",
      "##f 0\n",
      "[EMPTY] 0\n",
      "harry 1\n",
      "hi 1\n",
      "##nk 1\n",
      "##el 1\n",
      "united 0\n",
      "states 0\n",
      "[EMPTY] 0\n",
      "d 0\n",
      "##n 0\n",
      "##f 0\n"
     ]
    }
   ],
   "source": [
    "for id, prev_label in zip (encoding[\"input_ids\"][1], encoding[\"token_type_ids\"][1][:,3]):\n",
    "  if id != 0: # we skip padding tokens\n",
    "    print(tokenizer.decode([id]), prev_label.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wjVk49fO6u8H"
   },
   "source": [
    "This looks OK! Be sure to check this, because the token type ids are critical for the performance of TAPAS.\n",
    "\n",
    "Let's create a PyTorch dataset and corresponding dataloader. Note the __getitem__ method here: in order to properly set the prev_labels token types, we must check whether a table-question pair is the first in a sequence or not. In case it is, we can just encode it. In case it isn't, we need to encode it together with the previous table-question pair.\n",
    "\n",
    "Note that this is not the most efficient approach, because we're effectively tokenizing each table-question pair twice when applied on the entire dataset (feel free to ping me a more efficient solution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "C-n9vDTD1-k9"
   },
   "outputs": [],
   "source": [
    "class TableDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tokenizer):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.df.iloc[idx]\n",
    "        table = pd.read_csv(table_csv_path + item.table_file[9:]).astype(str) # TapasTokenizer expects the table data to be text only\n",
    "        if item.position != 0:\n",
    "          # use the previous table-question pair to correctly set the prev_labels token type ids\n",
    "          previous_item = self.df.iloc[idx-1]\n",
    "          encoding = self.tokenizer(table=table, \n",
    "                                    queries=[previous_item.question, item.question], \n",
    "                                    answer_coordinates=[previous_item.answer_coordinates, item.answer_coordinates], \n",
    "                                    answer_text=[previous_item.answer_text, item.answer_text],\n",
    "                                    padding=\"max_length\",\n",
    "                                    truncation=True,\n",
    "                                    return_tensors=\"pt\"\n",
    "          )\n",
    "          # use encodings of second table-question pair in the batch\n",
    "          encoding = {key: val[-1] for key, val in encoding.items()}\n",
    "        else:\n",
    "          # this means it's the first table-question pair in a sequence\n",
    "          encoding = self.tokenizer(table=table, \n",
    "                                    queries=item.question, \n",
    "                                    answer_coordinates=item.answer_coordinates, \n",
    "                                    answer_text=item.answer_text,\n",
    "                                    padding=\"max_length\",\n",
    "                                    truncation=True,\n",
    "                                    return_tensors=\"pt\"\n",
    "          )\n",
    "          # remove the batch dimension which the tokenizer adds \n",
    "          encoding = {key: val.squeeze(0) for key, val in encoding.items()}\n",
    "        return encoding\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "train_dataset = TableDataset(df=data, tokenizer=tokenizer)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X4CHgnTzwfNp",
    "outputId": "a0980f27-a317-4375-9bc4-0085acad0e5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 7])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][\"token_type_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bZN1psdBy5_s",
    "outputId": "e085d737-3a6f-45e5-c200-7c21916b284a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[1][\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "pHAyf85k_xQt"
   },
   "outputs": [],
   "source": [
    "batch = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FoqySHh-_0JV",
    "outputId": "9c0ab5d9-0a06-4331-80e2-ba3b739cfa92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g5pjJCCT_53N",
    "outputId": "d2ebbf1e-0701-47c1-8533-a087892bd715"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512, 7])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"token_type_ids\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVb1-H-jAEoS"
   },
   "source": [
    "Let's decode the first table-question pair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "id": "1vfjT1JC_7zI",
    "outputId": "f1a85d76-96ab-4a4d-f8ae-c7ee913c6d7f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] where are the players from? [SEP] pick player team position school 1 ben mcdonald baltimore orioles rhp louisiana state university 2 tyler houston atlanta braves c valley hs ( las vegas, nv ) 3 roger salkeld seattle mariners rhp saugus ( ca ) hs 4 jeff jackson philadelphia phillies of simeon hs ( chicago, il ) 5 donald harris texas rangers of texas tech university 6 paul coleman saint louis cardinals of frankston ( tx ) hs 7 frank thomas chicago white sox 1b auburn university 8 earl cunningham chicago cubs of lancaster ( sc ) hs 9 kyle abbott california angels lhp long beach state university 10 charles johnson montreal expos c westwood hs ( fort pierce, fl ) 11 calvin murray cleveland indians 3b w. t. white high school ( dallas, tx ) 12 jeff juden houston astros rhp salem ( ma ) hs 13 brent mayne kansas city royals c cal state fullerton 14 steve hosey san francisco giants of fresno state university 15 kiki jones los angeles dodgers rhp hillsborough hs ( tampa, fl ) 16 greg blosser boston red sox of sarasota ( fl ) hs 17 cal eldred milwaukee brewers rhp university of iowa 18 willie greene pittsburgh pirates ss jones county hs ( gray, ga ) 19 eddie zosky toronto blue jays ss fresno state university 20 scott bryant cincinnati reds of university of texas 21 greg gohr detroit tigers rhp santa clara university 22 tom goodwin los angeles dodgers of fresno state university 23 mo vaughn boston red sox 1b seton hall university 24 alan zinter new york mets c university of arizona 25 chuck knoblauch minnesota twins 2b texas a & m university 26 scott burrell seattle mariners rhp hamden ( ct ) hs [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(batch[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "sujsp8o9DtsY"
   },
   "outputs": [],
   "source": [
    "#first example should not have any prev_labels set\n",
    "assert batch[\"token_type_ids\"][0][:,3].sum() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EIeql5vfFI6s"
   },
   "source": [
    "Let's decode the second table-question pair and verify some more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "id": "WrNo_qMqFOzi",
    "outputId": "b2051f0b-72d8-42e2-a6b6-c5a40eda666f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] which player went to louisiana state university? [SEP] pick player team position school 1 ben mcdonald baltimore orioles rhp louisiana state university 2 tyler houston atlanta braves c valley hs ( las vegas, nv ) 3 roger salkeld seattle mariners rhp saugus ( ca ) hs 4 jeff jackson philadelphia phillies of simeon hs ( chicago, il ) 5 donald harris texas rangers of texas tech university 6 paul coleman saint louis cardinals of frankston ( tx ) hs 7 frank thomas chicago white sox 1b auburn university 8 earl cunningham chicago cubs of lancaster ( sc ) hs 9 kyle abbott california angels lhp long beach state university 10 charles johnson montreal expos c westwood hs ( fort pierce, fl ) 11 calvin murray cleveland indians 3b w. t. white high school ( dallas, tx ) 12 jeff juden houston astros rhp salem ( ma ) hs 13 brent mayne kansas city royals c cal state fullerton 14 steve hosey san francisco giants of fresno state university 15 kiki jones los angeles dodgers rhp hillsborough hs ( tampa, fl ) 16 greg blosser boston red sox of sarasota ( fl ) hs 17 cal eldred milwaukee brewers rhp university of iowa 18 willie greene pittsburgh pirates ss jones county hs ( gray, ga ) 19 eddie zosky toronto blue jays ss fresno state university 20 scott bryant cincinnati reds of university of texas 21 greg gohr detroit tigers rhp santa clara university 22 tom goodwin los angeles dodgers of fresno state university 23 mo vaughn boston red sox 1b seton hall university 24 alan zinter new york mets c university of arizona 25 chuck knoblauch minnesota twins 2b texas a & m university 26 scott burrell seattle mariners rhp hamden ( ct ) hs [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(batch[\"input_ids\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9a1OToVqxNap",
    "outputId": "2040d63a-024f-4e65-e17c-2a51630a9226"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(132)\n"
     ]
    }
   ],
   "source": [
    "assert batch[\"labels\"][0].sum() == batch[\"token_type_ids\"][1][:,3].sum()\n",
    "print(batch[\"token_type_ids\"][1][:,3].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x4PRdYvBE1k3",
    "outputId": "31bc6092-57e8-4040-f410-83e314ee4a0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] 0\n",
      "which 0\n",
      "player 0\n",
      "went 0\n",
      "to 0\n",
      "louisiana 0\n",
      "state 0\n",
      "university 0\n",
      "? 0\n",
      "[SEP] 0\n",
      "pick 0\n",
      "player 0\n",
      "team 0\n",
      "position 0\n",
      "school 0\n",
      "1 0\n",
      "ben 0\n",
      "mcdonald 0\n",
      "baltimore 0\n",
      "orioles 0\n",
      "r 0\n",
      "##hp 0\n",
      "louisiana 1\n",
      "state 1\n",
      "university 1\n",
      "2 0\n",
      "tyler 0\n",
      "houston 0\n",
      "atlanta 0\n",
      "braves 0\n",
      "c 0\n",
      "valley 1\n",
      "hs 1\n",
      "( 1\n",
      "las 1\n",
      "vegas 1\n",
      ", 1\n",
      "n 1\n",
      "##v 1\n",
      ") 1\n",
      "3 0\n",
      "roger 0\n",
      "sal 0\n",
      "##kel 0\n",
      "##d 0\n",
      "seattle 0\n",
      "mariners 0\n",
      "r 0\n",
      "##hp 0\n",
      "sa 1\n",
      "##ug 1\n",
      "##us 1\n",
      "( 1\n",
      "ca 1\n",
      ") 1\n",
      "hs 1\n",
      "4 0\n",
      "jeff 0\n",
      "jackson 0\n",
      "philadelphia 0\n",
      "phillies 0\n",
      "of 0\n",
      "simeon 1\n",
      "hs 1\n",
      "( 1\n",
      "chicago 1\n",
      ", 1\n",
      "il 1\n",
      ") 1\n",
      "5 0\n",
      "donald 0\n",
      "harris 0\n",
      "texas 0\n",
      "rangers 0\n",
      "of 0\n",
      "texas 1\n",
      "tech 1\n",
      "university 1\n",
      "6 0\n",
      "paul 0\n",
      "coleman 0\n",
      "saint 0\n",
      "louis 0\n",
      "cardinals 0\n",
      "of 0\n",
      "franks 1\n",
      "##ton 1\n",
      "( 1\n",
      "tx 1\n",
      ") 1\n",
      "hs 1\n",
      "7 0\n",
      "frank 0\n",
      "thomas 0\n",
      "chicago 0\n",
      "white 0\n",
      "sox 0\n",
      "1b 0\n",
      "auburn 1\n",
      "university 1\n",
      "8 0\n",
      "earl 0\n",
      "cunningham 0\n",
      "chicago 0\n",
      "cubs 0\n",
      "of 0\n",
      "lancaster 1\n",
      "( 1\n",
      "sc 1\n",
      ") 1\n",
      "hs 1\n",
      "9 0\n",
      "kyle 0\n",
      "abbott 0\n",
      "california 0\n",
      "angels 0\n",
      "l 0\n",
      "##hp 0\n",
      "long 1\n",
      "beach 1\n",
      "state 1\n",
      "university 1\n",
      "10 0\n",
      "charles 0\n",
      "johnson 0\n",
      "montreal 0\n",
      "expo 0\n",
      "##s 0\n",
      "c 0\n",
      "westwood 1\n",
      "hs 1\n",
      "( 1\n",
      "fort 1\n",
      "pierce 1\n",
      ", 1\n",
      "fl 1\n",
      ") 1\n",
      "11 0\n",
      "calvin 0\n",
      "murray 0\n",
      "cleveland 0\n",
      "indians 0\n",
      "3 0\n",
      "##b 0\n",
      "w 1\n",
      ". 1\n",
      "t 1\n",
      ". 1\n",
      "white 1\n",
      "high 1\n",
      "school 1\n",
      "( 1\n",
      "dallas 1\n",
      ", 1\n",
      "tx 1\n",
      ") 1\n",
      "12 0\n",
      "jeff 0\n",
      "jude 0\n",
      "##n 0\n",
      "houston 0\n",
      "astros 0\n",
      "r 0\n",
      "##hp 0\n",
      "salem 1\n",
      "( 1\n",
      "ma 1\n",
      ") 1\n",
      "hs 1\n",
      "13 0\n",
      "brent 0\n",
      "may 0\n",
      "##ne 0\n",
      "kansas 0\n",
      "city 0\n",
      "royals 0\n",
      "c 0\n",
      "cal 1\n",
      "state 1\n",
      "fuller 1\n",
      "##ton 1\n",
      "14 0\n",
      "steve 0\n",
      "hose 0\n",
      "##y 0\n",
      "san 0\n",
      "francisco 0\n",
      "giants 0\n",
      "of 0\n",
      "fresno 1\n",
      "state 1\n",
      "university 1\n",
      "15 0\n",
      "ki 0\n",
      "##ki 0\n",
      "jones 0\n",
      "los 0\n",
      "angeles 0\n",
      "dodgers 0\n",
      "r 0\n",
      "##hp 0\n",
      "hillsborough 1\n",
      "hs 1\n",
      "( 1\n",
      "tampa 1\n",
      ", 1\n",
      "fl 1\n",
      ") 1\n",
      "16 0\n",
      "greg 0\n",
      "b 0\n",
      "##los 0\n",
      "##ser 0\n",
      "boston 0\n",
      "red 0\n",
      "sox 0\n",
      "of 0\n",
      "sara 1\n",
      "##so 1\n",
      "##ta 1\n",
      "( 1\n",
      "fl 1\n",
      ") 1\n",
      "hs 1\n",
      "17 0\n",
      "cal 0\n",
      "el 0\n",
      "##dre 0\n",
      "##d 0\n",
      "milwaukee 0\n",
      "brewers 0\n",
      "r 0\n",
      "##hp 0\n",
      "university 1\n",
      "of 1\n",
      "iowa 1\n",
      "18 0\n",
      "willie 0\n",
      "greene 0\n",
      "pittsburgh 0\n",
      "pirates 0\n",
      "ss 0\n",
      "jones 1\n",
      "county 1\n",
      "hs 1\n",
      "( 1\n",
      "gray 1\n",
      ", 1\n",
      "ga 1\n",
      ") 1\n",
      "19 0\n",
      "eddie 0\n",
      "z 0\n",
      "##os 0\n",
      "##ky 0\n",
      "toronto 0\n",
      "blue 0\n",
      "jays 0\n",
      "ss 0\n",
      "fresno 1\n",
      "state 1\n",
      "university 1\n",
      "20 0\n",
      "scott 0\n",
      "bryant 0\n",
      "cincinnati 0\n",
      "reds 0\n",
      "of 0\n",
      "university 1\n",
      "of 1\n",
      "texas 1\n",
      "21 0\n",
      "greg 0\n",
      "go 0\n",
      "##hr 0\n",
      "detroit 0\n",
      "tigers 0\n",
      "r 0\n",
      "##hp 0\n",
      "santa 1\n",
      "clara 1\n",
      "university 1\n",
      "22 0\n",
      "tom 0\n",
      "goodwin 0\n",
      "los 0\n",
      "angeles 0\n",
      "dodgers 0\n",
      "of 0\n",
      "fresno 1\n",
      "state 1\n",
      "university 1\n",
      "23 0\n",
      "mo 0\n",
      "vaughn 0\n",
      "boston 0\n",
      "red 0\n",
      "sox 0\n",
      "1b 0\n",
      "seton 1\n",
      "hall 1\n",
      "university 1\n",
      "24 0\n",
      "alan 0\n",
      "z 0\n",
      "##int 0\n",
      "##er 0\n",
      "new 0\n",
      "york 0\n",
      "mets 0\n",
      "c 0\n",
      "university 1\n",
      "of 1\n",
      "arizona 1\n",
      "25 0\n",
      "chuck 0\n",
      "knob 0\n",
      "##lau 0\n",
      "##ch 0\n",
      "minnesota 0\n",
      "twins 0\n",
      "2 0\n",
      "##b 0\n",
      "texas 1\n",
      "a 1\n",
      "& 1\n",
      "m 1\n",
      "university 1\n",
      "26 0\n",
      "scott 0\n",
      "burr 0\n",
      "##ell 0\n",
      "seattle 0\n",
      "mariners 0\n",
      "r 0\n",
      "##hp 0\n",
      "ham 1\n",
      "##den 1\n",
      "( 1\n",
      "ct 1\n",
      ") 1\n",
      "hs 1\n"
     ]
    }
   ],
   "source": [
    "for id, prev_label in zip(batch[\"input_ids\"][1], batch[\"token_type_ids\"][1][:,3]):\n",
    "  if id != 0:\n",
    "    print(tokenizer.decode([id]), prev_label.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAem9QnIxoKb"
   },
   "source": [
    "## Define the model\n",
    "\n",
    "Here we initialize the model with a pre-trained base and randomly initialized cell selection head, and move it to the GPU (if available).\n",
    "\n",
    "Note that the `google/tapas-base` checkpoint has (by default) an SQA configuration, so we don't need to specify any additional hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "768723f1af4c4bf497064a9796567382",
      "82bfe5d88c5546358de33952e42221a3",
      "c6aadbda246d47fcad9660c2f57926a0",
      "cd910003940b498e94db9746091e4c3c",
      "a11bc2e0d34543d1bb0ab708e0cc1a67",
      "d59737fa0a424a90ba02110e4cf1b639",
      "d534c2ebdbb144efa59500fcadf6e118",
      "f6fef10b29f74c458d05c2cbda46bf4a",
      "695d0c44ebbe4a55a17c735645c26c82",
      "7e3cd6c49143436bad3d84be7ca2cf79",
      "be6159a5be0945629a517297df1170b8",
      "b889ffa28a1949e9ac46e205ee582688",
      "3c95dd6249784fe6a2a466737e5f5866",
      "cf9382ee988f4787a88340d3b2af95f3",
      "45fdca8a04f94b43b021c590181e8a48",
      "3bad5ab136084c2e92b55153828a403f"
     ]
    },
    "id": "_OsPodbiDliR",
    "outputId": "e2094861-fc6c-42b9-b12b-0f6824ad3048"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of TapasForQuestionAnswering were not initialized from the model checkpoint at google/tapas-base and are newly initialized: ['output_bias', 'output_weights', 'column_output_weights', 'column_output_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TapasForQuestionAnswering(\n",
       "  (tapas): TapasModel(\n",
       "    (embeddings): TapasEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(1024, 768)\n",
       "      (token_type_embeddings_0): Embedding(3, 768)\n",
       "      (token_type_embeddings_1): Embedding(256, 768)\n",
       "      (token_type_embeddings_2): Embedding(256, 768)\n",
       "      (token_type_embeddings_3): Embedding(2, 768)\n",
       "      (token_type_embeddings_4): Embedding(256, 768)\n",
       "      (token_type_embeddings_5): Embedding(256, 768)\n",
       "      (token_type_embeddings_6): Embedding(10, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.07, inplace=False)\n",
       "    )\n",
       "    (encoder): TapasEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): TapasLayer(\n",
       "          (attention): TapasAttention(\n",
       "            (self): TapasSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): TapasSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.07, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): TapasIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): TapasOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.07, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): TapasLayer(\n",
       "          (attention): TapasAttention(\n",
       "            (self): TapasSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): TapasSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.07, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): TapasIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): TapasOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.07, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): TapasLayer(\n",
       "          (attention): TapasAttention(\n",
       "            (self): TapasSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): TapasSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.07, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): TapasIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): TapasOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.07, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): TapasLayer(\n",
       "          (attention): TapasAttention(\n",
       "            (self): TapasSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): TapasSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.07, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): TapasIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): TapasOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.07, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): TapasLayer(\n",
       "          (attention): TapasAttention(\n",
       "            (self): TapasSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): TapasSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.07, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): TapasIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): TapasOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.07, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): TapasLayer(\n",
       "          (attention): TapasAttention(\n",
       "            (self): TapasSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): TapasSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.07, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): TapasIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): TapasOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.07, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): TapasLayer(\n",
       "          (attention): TapasAttention(\n",
       "            (self): TapasSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): TapasSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.07, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): TapasIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): TapasOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.07, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): TapasLayer(\n",
       "          (attention): TapasAttention(\n",
       "            (self): TapasSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): TapasSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.07, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): TapasIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): TapasOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.07, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): TapasLayer(\n",
       "          (attention): TapasAttention(\n",
       "            (self): TapasSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): TapasSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.07, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): TapasIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): TapasOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.07, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): TapasLayer(\n",
       "          (attention): TapasAttention(\n",
       "            (self): TapasSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): TapasSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.07, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): TapasIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): TapasOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.07, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): TapasLayer(\n",
       "          (attention): TapasAttention(\n",
       "            (self): TapasSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): TapasSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.07, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): TapasIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): TapasOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.07, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): TapasLayer(\n",
       "          (attention): TapasAttention(\n",
       "            (self): TapasSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): TapasSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.07, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): TapasIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): TapasOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.07, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): TapasPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.07, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TapasForQuestionAnswering\n",
    "\n",
    "model = TapasForQuestionAnswering.from_pretrained(\"google/tapas-base\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dtvkIFkCzdsg"
   },
   "source": [
    "## Training the model\n",
    "\n",
    "Let's fine-tune the model in well-known PyTorch fashion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HyEZVmbdzWV9",
    "outputId": "2a6c73a9-9572-480e-c24f-209e6c5804fb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hannahcatri/anaconda3/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Loss: 2.2924113273620605\n",
      "Loss: 1.7504932880401611\n",
      "Loss: 1.40304696559906\n",
      "Loss: 1.6494226455688477\n",
      "Loss: 1.6415494680404663\n",
      "Loss: 2.8653769493103027\n",
      "Loss: 2.4297642707824707\n",
      "Loss: 2.773843288421631\n",
      "Loss: 3.057562828063965\n",
      "Loss: 2.458859443664551\n",
      "Loss: 1.8117353916168213\n",
      "Loss: 1.8899388313293457\n",
      "Loss: 1.8997710943222046\n",
      "Loss: 1.2621345520019531\n",
      "Epoch: 1\n",
      "Loss: 2.557004690170288\n",
      "Loss: 1.0541355609893799\n",
      "Loss: 1.0075969696044922\n",
      "Loss: 1.716690182685852\n",
      "Loss: 1.8415734767913818\n",
      "Loss: 1.937148928642273\n",
      "Loss: 1.89765202999115\n",
      "Loss: 1.9327514171600342\n",
      "Loss: 2.027282476425171\n",
      "Loss: 1.077110767364502\n",
      "Loss: 1.1339160203933716\n",
      "Loss: 1.259394884109497\n",
      "Loss: 1.6109447479248047\n",
      "Loss: 0.9077013731002808\n",
      "Epoch: 2\n",
      "Loss: 2.0399744510650635\n",
      "Loss: 0.5073123574256897\n",
      "Loss: 0.6933571100234985\n",
      "Loss: 0.8221110105514526\n",
      "Loss: 1.2853317260742188\n",
      "Loss: 1.0606557130813599\n",
      "Loss: 1.1429767608642578\n",
      "Loss: 1.0728784799575806\n",
      "Loss: 1.4115822315216064\n",
      "Loss: 0.8682160377502441\n",
      "Loss: 0.9180620312690735\n",
      "Loss: 0.9426919221878052\n",
      "Loss: 1.0811737775802612\n",
      "Loss: 0.6229137182235718\n",
      "Epoch: 3\n",
      "Loss: 1.0673704147338867\n",
      "Loss: 0.552000880241394\n",
      "Loss: 0.3693353235721588\n",
      "Loss: 0.33179712295532227\n",
      "Loss: 0.5948972105979919\n",
      "Loss: 0.8096574544906616\n",
      "Loss: 0.7735267877578735\n",
      "Loss: 0.7665218114852905\n",
      "Loss: 1.9281198978424072\n",
      "Loss: 0.7558848857879639\n",
      "Loss: 0.44306546449661255\n",
      "Loss: 0.5309140682220459\n",
      "Loss: 0.7753393054008484\n",
      "Loss: 0.16037610173225403\n",
      "Epoch: 4\n",
      "Loss: 0.8017599582672119\n",
      "Loss: 0.2263784110546112\n",
      "Loss: 0.14881066977977753\n",
      "Loss: 0.3362227976322174\n",
      "Loss: 1.0723912715911865\n",
      "Loss: 0.3721447288990021\n",
      "Loss: 0.3761207163333893\n",
      "Loss: 0.5162474513053894\n",
      "Loss: 0.6805272698402405\n",
      "Loss: 0.6443378925323486\n",
      "Loss: 0.20984604954719543\n",
      "Loss: 0.9150679111480713\n",
      "Loss: 0.3766629099845886\n",
      "Loss: 0.3649662435054779\n",
      "Epoch: 5\n",
      "Loss: 0.7586000561714172\n",
      "Loss: 0.10743758827447891\n",
      "Loss: 0.07149256020784378\n",
      "Loss: 0.08011819422245026\n",
      "Loss: 0.41431984305381775\n",
      "Loss: 0.2782948911190033\n",
      "Loss: 0.22913818061351776\n",
      "Loss: 1.4416604042053223\n",
      "Loss: 1.031500220298767\n",
      "Loss: 1.0278339385986328\n",
      "Loss: 0.33454644680023193\n",
      "Loss: 0.8181592226028442\n",
      "Loss: 0.4133422076702118\n",
      "Loss: 0.2084549069404602\n",
      "Epoch: 6\n",
      "Loss: 0.21906252205371857\n",
      "Loss: 0.11221723258495331\n",
      "Loss: 0.10076890140771866\n",
      "Loss: 0.19348712265491486\n",
      "Loss: 1.571136713027954\n",
      "Loss: 0.6059613227844238\n",
      "Loss: 0.3346498906612396\n",
      "Loss: 0.9296775460243225\n",
      "Loss: 1.0222256183624268\n",
      "Loss: 1.297646164894104\n",
      "Loss: 0.2463739514350891\n",
      "Loss: 0.7136691808700562\n",
      "Loss: 0.7088658809661865\n",
      "Loss: 0.1695186197757721\n",
      "Epoch: 7\n",
      "Loss: 0.17165538668632507\n",
      "Loss: 0.07268370687961578\n",
      "Loss: 0.06881818175315857\n",
      "Loss: 0.11151423305273056\n",
      "Loss: 1.6429965496063232\n",
      "Loss: 0.18232125043869019\n",
      "Loss: 1.8422945737838745\n",
      "Loss: 0.9902552366256714\n",
      "Loss: 1.414494514465332\n",
      "Loss: 0.5535725951194763\n",
      "Loss: 0.22298341989517212\n",
      "Loss: 0.2581028342247009\n",
      "Loss: 0.45502087473869324\n",
      "Loss: 0.7309158444404602\n",
      "Epoch: 8\n",
      "Loss: 0.49484264850616455\n",
      "Loss: 0.2788221836090088\n",
      "Loss: 0.14162835478782654\n",
      "Loss: 0.8758519887924194\n",
      "Loss: 5.020141124725342\n",
      "Loss: 1.6216018199920654\n",
      "Loss: 0.2575623393058777\n",
      "Loss: 1.097074031829834\n",
      "Loss: 0.9318841695785522\n",
      "Loss: 0.9370157718658447\n",
      "Loss: 0.5047136545181274\n",
      "Loss: 1.0254721641540527\n",
      "Loss: 0.7624860405921936\n",
      "Loss: 1.1207149028778076\n",
      "Epoch: 9\n",
      "Loss: 1.7915198802947998\n",
      "Loss: 0.2063177227973938\n",
      "Loss: 0.35353100299835205\n",
      "Loss: 0.19763562083244324\n",
      "Loss: 0.27723613381385803\n",
      "Loss: 0.5594111680984497\n",
      "Loss: 2.8892111778259277\n",
      "Loss: 0.8140338659286499\n",
      "Loss: 0.1812877357006073\n",
      "Loss: 0.5441843867301941\n",
      "Loss: 1.7070870399475098\n",
      "Loss: 0.6036044359207153\n",
      "Loss: 1.9243254661560059\n",
      "Loss: 1.3623530864715576\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "   print(\"Epoch:\", epoch)\n",
    "   for idx, batch in enumerate(train_dataloader):\n",
    "        # get the inputs;\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        token_type_ids = batch[\"token_type_ids\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids,\n",
    "                       labels=labels)\n",
    "        loss = outputs.loss\n",
    "        print(\"Loss:\", loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmugNHCN20QF"
   },
   "source": [
    "## Inference\n",
    "\n",
    "As SQA is a bit different due to its conversational nature, we need to run every training example of the a batch one by one through the model (sequentially), overwriting the `prev_labels` token types (which were created by the tokenizer) by the answer predicted by the model. It is based on the [following code](https://github.com/google-research/tapas/blob/f458b6624b8aa75961a0ab78e9847355022940d3/tapas/experiments/prediction_utils.py#L92) from the official implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "MhJwoaSy26PD"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "def compute_prediction_sequence(model, data, device):\n",
    "  \"\"\"Computes predictions using model's answers to the previous questions.\"\"\"\n",
    "  \n",
    "  # prepare data\n",
    "  input_ids = data[\"input_ids\"].to(device)\n",
    "  attention_mask = data[\"attention_mask\"].to(device)\n",
    "  token_type_ids = data[\"token_type_ids\"].to(device)\n",
    "\n",
    "  all_logits = []\n",
    "  prev_answers = None\n",
    "\n",
    "  num_batch = data[\"input_ids\"].shape[0]\n",
    "  \n",
    "  for idx in range(num_batch):\n",
    "    \n",
    "    if prev_answers is not None:\n",
    "        coords_to_answer = prev_answers[idx]\n",
    "        # Next, set the label ids predicted by the model\n",
    "        prev_label_ids_example = token_type_ids_example[:,3] # shape (seq_len,)\n",
    "        model_label_ids = np.zeros_like(prev_label_ids_example.cpu().numpy()) # shape (seq_len,)\n",
    "\n",
    "        # for each token in the sequence:\n",
    "        token_type_ids_example = token_type_ids[idx] # shape (seq_len, 7)\n",
    "        for i in range(model_label_ids.shape[0]):\n",
    "          segment_id = token_type_ids_example[:,0].tolist()[i]\n",
    "          col_id = token_type_ids_example[:,1].tolist()[i] - 1\n",
    "          row_id = token_type_ids_example[:,2].tolist()[i] - 1\n",
    "          if row_id >= 0 and col_id >= 0 and segment_id == 1:\n",
    "            model_label_ids[i] = int(coords_to_answer[(col_id, row_id)])\n",
    "\n",
    "        # set the prev label ids of the example (shape (1, seq_len) )\n",
    "        token_type_ids_example[:,3] = torch.from_numpy(model_label_ids).type(torch.long).to(device)   \n",
    "\n",
    "    prev_answers = {}\n",
    "    # get the example\n",
    "    input_ids_example = input_ids[idx] # shape (seq_len,)\n",
    "    attention_mask_example = attention_mask[idx] # shape (seq_len,)\n",
    "    token_type_ids_example = token_type_ids[idx] # shape (seq_len, 7)\n",
    "    # forward pass to obtain the logits\n",
    "    outputs = model(input_ids=input_ids_example.unsqueeze(0), \n",
    "                    attention_mask=attention_mask_example.unsqueeze(0), \n",
    "                    token_type_ids=token_type_ids_example.unsqueeze(0))\n",
    "    logits = outputs.logits\n",
    "    all_logits.append(logits)\n",
    "\n",
    "    # convert logits to probabilities (which are of shape (1, seq_len))\n",
    "    dist_per_token = torch.distributions.Bernoulli(logits=logits)\n",
    "    probabilities = dist_per_token.probs * attention_mask_example.type(torch.float32).to(dist_per_token.probs.device) \n",
    "\n",
    "    # Compute average probability per cell, aggregating over tokens.\n",
    "    # Dictionary maps coordinates to a list of one or more probabilities\n",
    "    coords_to_probs = collections.defaultdict(list)\n",
    "    prev_answers = {}\n",
    "    for i, p in enumerate(probabilities.squeeze().tolist()):\n",
    "      segment_id = token_type_ids_example[:,0].tolist()[i]\n",
    "      col = token_type_ids_example[:,1].tolist()[i] - 1\n",
    "      row = token_type_ids_example[:,2].tolist()[i] - 1\n",
    "      if col >= 0 and row >= 0 and segment_id == 1:\n",
    "        coords_to_probs[(col, row)].append(p)\n",
    "\n",
    "    # Next, map cell coordinates to 1 or 0 (depending on whether the mean prob of all cell tokens is > 0.5)\n",
    "    coords_to_answer = {}\n",
    "    for key in coords_to_probs:\n",
    "      coords_to_answer[key] = np.array(coords_to_probs[key]).mean() > 0.5\n",
    "    prev_answers[idx+1] = coords_to_answer\n",
    "    \n",
    "  logits_batch = torch.cat(tuple(all_logits), 0)\n",
    "  \n",
    "  return logits_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "jflxDE_BfVg9"
   },
   "outputs": [],
   "source": [
    "data = {'Actors': [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"], \n",
    "        'Age': [\"56\", \"45\", \"59\"],\n",
    "        'Number of movies': [\"87\", \"53\", \"69\"],\n",
    "        'Date of birth': [\"7 february 1967\", \"10 june 1996\", \"28 november 1967\"]}\n",
    "queries = [\"How many movies has George Clooney played in?\", \"How old is he?\", \"What's his date of birth?\"]\n",
    "\n",
    "table = pd.DataFrame.from_dict(data)\n",
    "\n",
    "inputs = tokenizer(table=table, queries=queries, padding='max_length', return_tensors=\"pt\")\n",
    "logits = compute_prediction_sequence(model, inputs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actors</th>\n",
       "      <th>Age</th>\n",
       "      <th>Number of movies</th>\n",
       "      <th>Date of birth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brad Pitt</td>\n",
       "      <td>56</td>\n",
       "      <td>87</td>\n",
       "      <td>7 february 1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Leonardo Di Caprio</td>\n",
       "      <td>45</td>\n",
       "      <td>53</td>\n",
       "      <td>10 june 1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>George Clooney</td>\n",
       "      <td>59</td>\n",
       "      <td>69</td>\n",
       "      <td>28 november 1967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Actors Age Number of movies     Date of birth\n",
       "0           Brad Pitt  56               87   7 february 1967\n",
       "1  Leonardo Di Caprio  45               53      10 june 1996\n",
       "2      George Clooney  59               69  28 november 1967"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'Actors': [\"Brad Pitt\", \"Leonardo Di Caprio\", \"George Clooney\"], \n",
    "        'Age': [\"56\", \"45\", \"59\"],\n",
    "        'Number of movies': [\"87\", \"53\", \"69\"],\n",
    "        'Date of birth': [\"7 february 1967\", \"10 june 1996\", \"28 november 1967\"]}\n",
    "queries = [\"How many movies has George Clooney played in?\", \"How old is he?\", \"What's his date of birth?\"]\n",
    "\n",
    "table = pd.DataFrame.from_dict(data)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(table=table, queries=queries, padding='max_length', return_tensors=\"pt\")\n",
    "logits = compute_prediction_sequence(model, inputs, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k_a_Y-rDq__o"
   },
   "source": [
    "Finally, we can use the handy `convert_logits_to_predictions` function of `TapasTokenizer` to convert the logits into predicted coordinates, and print out the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "5fAcNOVsqoVD"
   },
   "outputs": [],
   "source": [
    "predicted_answer_coordinates, = tokenizer.convert_logits_to_predictions(inputs, logits.cpu().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "id": "QP4AHMxFujhV",
    "outputId": "aed2fc99-957b-4b9f-e804-b426a80de8df"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actors</th>\n",
       "      <th>Age</th>\n",
       "      <th>Number of movies</th>\n",
       "      <th>Date of birth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brad Pitt</td>\n",
       "      <td>56</td>\n",
       "      <td>87</td>\n",
       "      <td>7 february 1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Leonardo Di Caprio</td>\n",
       "      <td>45</td>\n",
       "      <td>53</td>\n",
       "      <td>10 june 1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>George Clooney</td>\n",
       "      <td>59</td>\n",
       "      <td>69</td>\n",
       "      <td>28 november 1967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Actors Age Number of movies     Date of birth\n",
       "0           Brad Pitt  56               87   7 february 1967\n",
       "1  Leonardo Di Caprio  45               53      10 june 1996\n",
       "2      George Clooney  59               69  28 november 1967"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "How many movies has George Clooney played in?\n",
      "Predicted answer: Brad Pitt, Leonardo Di Caprio, George Clooney\n",
      "How old is he?\n",
      "Predicted answer: Brad Pitt, Leonardo Di Caprio, George Clooney\n",
      "What's his date of birth?\n",
      "Predicted answer: 7 february 1967, 10 june 1996, 28 november 1967\n"
     ]
    }
   ],
   "source": [
    "# handy helper function in case inference on Pandas dataframe\n",
    "answers = []\n",
    "for coordinates in predicted_answer_coordinates:\n",
    "  if len(coordinates) == 1:\n",
    "    # only a single cell:\n",
    "    answers.append(table.iat[coordinates[0]])\n",
    "  else:\n",
    "    # multiple cells\n",
    "    cell_values = []\n",
    "    for coordinate in coordinates:\n",
    "      cell_values.append(table.iat[coordinate])\n",
    "    answers.append(\", \".join(cell_values))\n",
    "\n",
    "display(table)\n",
    "print(\"\")\n",
    "for query, answer in zip(queries, answers):\n",
    "  print(query)\n",
    "  print(\"Predicted answer: \" + answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6L0KBaPjG7uj"
   },
   "source": [
    "Note that the results here are not correct, that's obvious since we only trained on 28 examples and tested it on an entire different example. In reality, you should train on the entire dataset. The result of this is the `google/tapas-base-finetuned-sqa` checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of incidents in the set is 7562\n",
      "(7562, 34)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>call_number</th>\n",
       "      <th>unit_id</th>\n",
       "      <th>incident_number</th>\n",
       "      <th>call_type</th>\n",
       "      <th>call_date</th>\n",
       "      <th>watch_date</th>\n",
       "      <th>received_dttm</th>\n",
       "      <th>entry_dttm</th>\n",
       "      <th>dispatch_dttm</th>\n",
       "      <th>response_dttm</th>\n",
       "      <th>...</th>\n",
       "      <th>number_of_alarms</th>\n",
       "      <th>unit_type</th>\n",
       "      <th>unit_sequence_in_call_dispatch</th>\n",
       "      <th>fire_prevention_district</th>\n",
       "      <th>supervisor_district</th>\n",
       "      <th>neighborhoods_analysis_boundaries</th>\n",
       "      <th>rowid</th>\n",
       "      <th>case_location</th>\n",
       "      <th>transport_dttm</th>\n",
       "      <th>hospital_dttm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7199</th>\n",
       "      <td>220312124</td>\n",
       "      <td>B03</td>\n",
       "      <td>22014641</td>\n",
       "      <td>Alarms</td>\n",
       "      <td>2022-01-31T00:00:00.000</td>\n",
       "      <td>2022-01-31T00:00:00.000</td>\n",
       "      <td>2022-01-31T15:57:07.000</td>\n",
       "      <td>2022-01-31T15:58:35.000</td>\n",
       "      <td>2022-01-31T15:58:41.000</td>\n",
       "      <td>2022-01-31T15:59:38.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>CHIEF</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>Financial District/South Beach</td>\n",
       "      <td>220312124-B03</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-122.3890405...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4335</th>\n",
       "      <td>220283288</td>\n",
       "      <td>E14</td>\n",
       "      <td>22013457</td>\n",
       "      <td>Medical Incident</td>\n",
       "      <td>2022-01-28T00:00:00.000</td>\n",
       "      <td>2022-01-28T00:00:00.000</td>\n",
       "      <td>2022-01-28T22:06:51.000</td>\n",
       "      <td>2022-01-28T22:08:06.000</td>\n",
       "      <td>2022-01-28T22:08:18.000</td>\n",
       "      <td>2022-01-28T22:09:48.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>ENGINE</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Outer Richmond</td>\n",
       "      <td>220283288-E14</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-122.4876801...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>220232062</td>\n",
       "      <td>B08</td>\n",
       "      <td>22010996</td>\n",
       "      <td>Alarms</td>\n",
       "      <td>2022-01-23T00:00:00.000</td>\n",
       "      <td>2022-01-23T00:00:00.000</td>\n",
       "      <td>2022-01-23T16:32:31.000</td>\n",
       "      <td>2022-01-23T16:33:47.000</td>\n",
       "      <td>2022-01-23T16:33:55.000</td>\n",
       "      <td>2022-01-23T16:36:32.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>CHIEF</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>West of Twin Peaks</td>\n",
       "      <td>220232062-B08</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-122.4628171...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466</th>\n",
       "      <td>220250347</td>\n",
       "      <td>E18</td>\n",
       "      <td>22011675</td>\n",
       "      <td>Medical Incident</td>\n",
       "      <td>2022-01-25T00:00:00.000</td>\n",
       "      <td>2022-01-24T00:00:00.000</td>\n",
       "      <td>2022-01-25T05:49:07.000</td>\n",
       "      <td>2022-01-25T05:51:29.000</td>\n",
       "      <td>2022-01-25T05:51:53.000</td>\n",
       "      <td>2022-01-25T05:53:26.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>ENGINE</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4</td>\n",
       "      <td>Sunset/Parkside</td>\n",
       "      <td>220250347-E18</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-122.4829669...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>220232887</td>\n",
       "      <td>58</td>\n",
       "      <td>22011108</td>\n",
       "      <td>Medical Incident</td>\n",
       "      <td>2022-01-23T00:00:00.000</td>\n",
       "      <td>2022-01-23T00:00:00.000</td>\n",
       "      <td>2022-01-23T21:26:04.000</td>\n",
       "      <td>2022-01-23T21:28:52.000</td>\n",
       "      <td>2022-01-23T21:29:01.000</td>\n",
       "      <td>2022-01-23T21:31:01.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>MEDIC</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>Tenderloin</td>\n",
       "      <td>220232887-58</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-122.4126203...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      call_number unit_id  incident_number         call_type  \\\n",
       "7199    220312124     B03         22014641            Alarms   \n",
       "4335    220283288     E14         22013457  Medical Incident   \n",
       "337     220232062     B08         22010996            Alarms   \n",
       "2466    220250347     E18         22011675  Medical Incident   \n",
       "151     220232887      58         22011108  Medical Incident   \n",
       "\n",
       "                    call_date               watch_date  \\\n",
       "7199  2022-01-31T00:00:00.000  2022-01-31T00:00:00.000   \n",
       "4335  2022-01-28T00:00:00.000  2022-01-28T00:00:00.000   \n",
       "337   2022-01-23T00:00:00.000  2022-01-23T00:00:00.000   \n",
       "2466  2022-01-25T00:00:00.000  2022-01-24T00:00:00.000   \n",
       "151   2022-01-23T00:00:00.000  2022-01-23T00:00:00.000   \n",
       "\n",
       "                received_dttm               entry_dttm  \\\n",
       "7199  2022-01-31T15:57:07.000  2022-01-31T15:58:35.000   \n",
       "4335  2022-01-28T22:06:51.000  2022-01-28T22:08:06.000   \n",
       "337   2022-01-23T16:32:31.000  2022-01-23T16:33:47.000   \n",
       "2466  2022-01-25T05:49:07.000  2022-01-25T05:51:29.000   \n",
       "151   2022-01-23T21:26:04.000  2022-01-23T21:28:52.000   \n",
       "\n",
       "                dispatch_dttm            response_dttm  ... number_of_alarms  \\\n",
       "7199  2022-01-31T15:58:41.000  2022-01-31T15:59:38.000  ...                1   \n",
       "4335  2022-01-28T22:08:18.000  2022-01-28T22:09:48.000  ...                1   \n",
       "337   2022-01-23T16:33:55.000  2022-01-23T16:36:32.000  ...                1   \n",
       "2466  2022-01-25T05:51:53.000  2022-01-25T05:53:26.000  ...                1   \n",
       "151   2022-01-23T21:29:01.000  2022-01-23T21:31:01.000  ...                1   \n",
       "\n",
       "     unit_type unit_sequence_in_call_dispatch fire_prevention_district  \\\n",
       "7199     CHIEF                              1                        3   \n",
       "4335    ENGINE                              1                        7   \n",
       "337      CHIEF                              1                        8   \n",
       "2466    ENGINE                              1                      8.0   \n",
       "151      MEDIC                              1                        3   \n",
       "\n",
       "     supervisor_district  neighborhoods_analysis_boundaries          rowid  \\\n",
       "7199                   6     Financial District/South Beach  220312124-B03   \n",
       "4335                   1                     Outer Richmond  220283288-E14   \n",
       "337                    7                 West of Twin Peaks  220232062-B08   \n",
       "2466                   4                    Sunset/Parkside  220250347-E18   \n",
       "151                    6                         Tenderloin   220232887-58   \n",
       "\n",
       "                                          case_location  transport_dttm  \\\n",
       "7199  {'type': 'Point', 'coordinates': [-122.3890405...             NaN   \n",
       "4335  {'type': 'Point', 'coordinates': [-122.4876801...             NaN   \n",
       "337   {'type': 'Point', 'coordinates': [-122.4628171...             NaN   \n",
       "2466  {'type': 'Point', 'coordinates': [-122.4829669...             NaN   \n",
       "151   {'type': 'Point', 'coordinates': [-122.4126203...             NaN   \n",
       "\n",
       "     hospital_dttm  \n",
       "7199           NaN  \n",
       "4335           NaN  \n",
       "337            NaN  \n",
       "2466           NaN  \n",
       "151            NaN  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "# set 10 day lookback window\n",
    "periodend = datetime.datetime.now().isoformat()\n",
    "periodstart = (datetime.datetime.now()- datetime.timedelta(days=10)).isoformat()\n",
    "#Get count of incidents to determine limit to retrieve\n",
    "num=pd.read_json(\"https://data.sfgov.org/resource/RowID.json?$select=COUNT(incident_number)&$where=call_date%20between%20%27\"\n",
    "                 +str(periodstart)+\"%27%20AND%20%27\"+str(periodend)+\"%27\")\n",
    "maxNumber=num.iloc[0,0]\n",
    "print('The number of incidents in the set is',maxNumber)\n",
    "# Use record to write query call to API to get all incidents needed/bypass API default of 1000\n",
    "query_str=(\"https://data.sfgov.org/resource/RowID.json?$where=call_date%20between%20%27\"\n",
    "           +str(periodstart)+\"%27%20AND%20%27\"\n",
    "           +str(periodend)+\"%27&$limit=\"+str(maxNumber))\n",
    "cfs_data=pd.read_json(query_str)\n",
    "print(cfs_data.shape)\n",
    "cfs_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>call_number</th>\n",
       "      <th>unit_id</th>\n",
       "      <th>incident_number</th>\n",
       "      <th>incident</th>\n",
       "      <th>call_date</th>\n",
       "      <th>watch_date</th>\n",
       "      <th>received_dttm</th>\n",
       "      <th>entry_dttm</th>\n",
       "      <th>dispatch_dttm</th>\n",
       "      <th>response_dttm</th>\n",
       "      <th>...</th>\n",
       "      <th>number_of_alarms</th>\n",
       "      <th>unit_type</th>\n",
       "      <th>unit_sequence_in_call_dispatch</th>\n",
       "      <th>fire_prevention_district</th>\n",
       "      <th>supervisor_district</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>rowid</th>\n",
       "      <th>case_location</th>\n",
       "      <th>transport_dttm</th>\n",
       "      <th>hospital_dttm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220230253</td>\n",
       "      <td>SCRT6</td>\n",
       "      <td>22010754</td>\n",
       "      <td>Medical Incident</td>\n",
       "      <td>2022-01-23T00:00:00.000</td>\n",
       "      <td>2022-01-22T00:00:00.000</td>\n",
       "      <td>2022-01-23T02:07:33.000</td>\n",
       "      <td>2022-01-23T02:14:09.000</td>\n",
       "      <td>2022-01-23T02:20:00.000</td>\n",
       "      <td>2022-01-23T02:20:00.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>SUPPORT</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>Mission</td>\n",
       "      <td>220230253-SCRT6</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-122.4190886...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220230206</td>\n",
       "      <td>63</td>\n",
       "      <td>22010747</td>\n",
       "      <td>Medical Incident</td>\n",
       "      <td>2022-01-23T00:00:00.000</td>\n",
       "      <td>2022-01-22T00:00:00.000</td>\n",
       "      <td>2022-01-23T01:48:31.000</td>\n",
       "      <td>2022-01-23T01:49:49.000</td>\n",
       "      <td>2022-01-23T01:51:07.000</td>\n",
       "      <td>2022-01-23T01:51:10.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>MEDIC</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>Tenderloin</td>\n",
       "      <td>220230206-63</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-122.4173655...</td>\n",
       "      <td>2022-01-23T02:16:10.000</td>\n",
       "      <td>2022-01-23T02:26:22.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220230288</td>\n",
       "      <td>E03</td>\n",
       "      <td>22010764</td>\n",
       "      <td>Medical Incident</td>\n",
       "      <td>2022-01-23T00:00:00.000</td>\n",
       "      <td>2022-01-22T00:00:00.000</td>\n",
       "      <td>2022-01-23T02:35:05.000</td>\n",
       "      <td>2022-01-23T02:37:31.000</td>\n",
       "      <td>2022-01-23T02:40:50.000</td>\n",
       "      <td>2022-01-23T02:40:50.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>ENGINE</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>Tenderloin</td>\n",
       "      <td>220230288-E03</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-122.4162597...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220230165</td>\n",
       "      <td>T17</td>\n",
       "      <td>22010739</td>\n",
       "      <td>Medical Incident</td>\n",
       "      <td>2022-01-23T00:00:00.000</td>\n",
       "      <td>2022-01-22T00:00:00.000</td>\n",
       "      <td>2022-01-23T01:27:16.000</td>\n",
       "      <td>2022-01-23T01:28:11.000</td>\n",
       "      <td>2022-01-23T01:28:27.000</td>\n",
       "      <td>2022-01-23T01:30:39.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>TRUCK</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>Bayview Hunters Point</td>\n",
       "      <td>220230165-T17</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-122.3982982...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220230127</td>\n",
       "      <td>E03</td>\n",
       "      <td>22010728</td>\n",
       "      <td>Medical Incident</td>\n",
       "      <td>2022-01-23T00:00:00.000</td>\n",
       "      <td>2022-01-22T00:00:00.000</td>\n",
       "      <td>2022-01-23T01:05:18.000</td>\n",
       "      <td>2022-01-23T01:06:04.000</td>\n",
       "      <td>2022-01-23T01:06:42.000</td>\n",
       "      <td>2022-01-23T01:09:18.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>ENGINE</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>Tenderloin</td>\n",
       "      <td>220230127-E03</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-122.4172576...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7557</th>\n",
       "      <td>220320063</td>\n",
       "      <td>76</td>\n",
       "      <td>22014828</td>\n",
       "      <td>Medical Incident</td>\n",
       "      <td>2022-02-01T00:00:00.000</td>\n",
       "      <td>2022-01-31T00:00:00.000</td>\n",
       "      <td>2022-02-01T00:56:50.000</td>\n",
       "      <td>2022-02-01T00:59:22.000</td>\n",
       "      <td>2022-02-01T01:00:13.000</td>\n",
       "      <td>2022-02-01T01:00:19.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>MEDIC</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>Outer Mission</td>\n",
       "      <td>220320063-76</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-122.4491688...</td>\n",
       "      <td>2022-02-01T01:21:52.000</td>\n",
       "      <td>2022-02-01T01:41:49.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7558</th>\n",
       "      <td>220320084</td>\n",
       "      <td>58</td>\n",
       "      <td>22014833</td>\n",
       "      <td>Medical Incident</td>\n",
       "      <td>2022-02-01T00:00:00.000</td>\n",
       "      <td>2022-01-31T00:00:00.000</td>\n",
       "      <td>2022-02-01T01:18:57.000</td>\n",
       "      <td>2022-02-01T01:20:55.000</td>\n",
       "      <td>2022-02-01T01:21:09.000</td>\n",
       "      <td>2022-02-01T01:21:12.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>MEDIC</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>Lakeshore</td>\n",
       "      <td>220320084-58</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-122.4788651...</td>\n",
       "      <td>2022-02-01T01:48:18.000</td>\n",
       "      <td>2022-02-01T02:24:51.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7559</th>\n",
       "      <td>220320127</td>\n",
       "      <td>AM120</td>\n",
       "      <td>22014839</td>\n",
       "      <td>Medical Incident</td>\n",
       "      <td>2022-02-01T00:00:00.000</td>\n",
       "      <td>2022-01-31T00:00:00.000</td>\n",
       "      <td>2022-02-01T02:17:27.000</td>\n",
       "      <td>2022-02-01T02:19:34.000</td>\n",
       "      <td>2022-02-01T02:20:10.000</td>\n",
       "      <td>2022-02-01T02:27:52.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>PRIVATE</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Western Addition</td>\n",
       "      <td>220320127-AM120</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-122.4408636...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7560</th>\n",
       "      <td>220320152</td>\n",
       "      <td>KM104</td>\n",
       "      <td>22014846</td>\n",
       "      <td>Medical Incident</td>\n",
       "      <td>2022-02-01T00:00:00.000</td>\n",
       "      <td>2022-01-31T00:00:00.000</td>\n",
       "      <td>2022-02-01T02:51:17.000</td>\n",
       "      <td>2022-02-01T02:52:18.000</td>\n",
       "      <td>2022-02-01T02:52:46.000</td>\n",
       "      <td>2022-02-01T02:56:09.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>PRIVATE</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>Sunset/Parkside</td>\n",
       "      <td>220320152-KM104</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-122.4976191...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7561</th>\n",
       "      <td>220320134</td>\n",
       "      <td>RC1</td>\n",
       "      <td>22014841</td>\n",
       "      <td>Medical Incident</td>\n",
       "      <td>2022-02-01T00:00:00.000</td>\n",
       "      <td>2022-01-31T00:00:00.000</td>\n",
       "      <td>2022-02-01T02:27:48.000</td>\n",
       "      <td>2022-02-01T02:29:34.000</td>\n",
       "      <td>2022-02-01T02:30:30.000</td>\n",
       "      <td>2022-02-01T02:32:58.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>RESCUE CAPTAIN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>South of Market</td>\n",
       "      <td>220320134-RC1</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-122.4059313...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7562 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      call_number unit_id  incident_number          incident  \\\n",
       "0       220230253   SCRT6         22010754  Medical Incident   \n",
       "1       220230206      63         22010747  Medical Incident   \n",
       "2       220230288     E03         22010764  Medical Incident   \n",
       "3       220230165     T17         22010739  Medical Incident   \n",
       "4       220230127     E03         22010728  Medical Incident   \n",
       "...           ...     ...              ...               ...   \n",
       "7557    220320063      76         22014828  Medical Incident   \n",
       "7558    220320084      58         22014833  Medical Incident   \n",
       "7559    220320127   AM120         22014839  Medical Incident   \n",
       "7560    220320152   KM104         22014846  Medical Incident   \n",
       "7561    220320134     RC1         22014841  Medical Incident   \n",
       "\n",
       "                    call_date               watch_date  \\\n",
       "0     2022-01-23T00:00:00.000  2022-01-22T00:00:00.000   \n",
       "1     2022-01-23T00:00:00.000  2022-01-22T00:00:00.000   \n",
       "2     2022-01-23T00:00:00.000  2022-01-22T00:00:00.000   \n",
       "3     2022-01-23T00:00:00.000  2022-01-22T00:00:00.000   \n",
       "4     2022-01-23T00:00:00.000  2022-01-22T00:00:00.000   \n",
       "...                       ...                      ...   \n",
       "7557  2022-02-01T00:00:00.000  2022-01-31T00:00:00.000   \n",
       "7558  2022-02-01T00:00:00.000  2022-01-31T00:00:00.000   \n",
       "7559  2022-02-01T00:00:00.000  2022-01-31T00:00:00.000   \n",
       "7560  2022-02-01T00:00:00.000  2022-01-31T00:00:00.000   \n",
       "7561  2022-02-01T00:00:00.000  2022-01-31T00:00:00.000   \n",
       "\n",
       "                received_dttm               entry_dttm  \\\n",
       "0     2022-01-23T02:07:33.000  2022-01-23T02:14:09.000   \n",
       "1     2022-01-23T01:48:31.000  2022-01-23T01:49:49.000   \n",
       "2     2022-01-23T02:35:05.000  2022-01-23T02:37:31.000   \n",
       "3     2022-01-23T01:27:16.000  2022-01-23T01:28:11.000   \n",
       "4     2022-01-23T01:05:18.000  2022-01-23T01:06:04.000   \n",
       "...                       ...                      ...   \n",
       "7557  2022-02-01T00:56:50.000  2022-02-01T00:59:22.000   \n",
       "7558  2022-02-01T01:18:57.000  2022-02-01T01:20:55.000   \n",
       "7559  2022-02-01T02:17:27.000  2022-02-01T02:19:34.000   \n",
       "7560  2022-02-01T02:51:17.000  2022-02-01T02:52:18.000   \n",
       "7561  2022-02-01T02:27:48.000  2022-02-01T02:29:34.000   \n",
       "\n",
       "                dispatch_dttm            response_dttm  ... number_of_alarms  \\\n",
       "0     2022-01-23T02:20:00.000  2022-01-23T02:20:00.000  ...                1   \n",
       "1     2022-01-23T01:51:07.000  2022-01-23T01:51:10.000  ...                1   \n",
       "2     2022-01-23T02:40:50.000  2022-01-23T02:40:50.000  ...                1   \n",
       "3     2022-01-23T01:28:27.000  2022-01-23T01:30:39.000  ...                1   \n",
       "4     2022-01-23T01:06:42.000  2022-01-23T01:09:18.000  ...                1   \n",
       "...                       ...                      ...  ...              ...   \n",
       "7557  2022-02-01T01:00:13.000  2022-02-01T01:00:19.000  ...                1   \n",
       "7558  2022-02-01T01:21:09.000  2022-02-01T01:21:12.000  ...                1   \n",
       "7559  2022-02-01T02:20:10.000  2022-02-01T02:27:52.000  ...                1   \n",
       "7560  2022-02-01T02:52:46.000  2022-02-01T02:56:09.000  ...                1   \n",
       "7561  2022-02-01T02:30:30.000  2022-02-01T02:32:58.000  ...                1   \n",
       "\n",
       "           unit_type unit_sequence_in_call_dispatch fire_prevention_district  \\\n",
       "0            SUPPORT                              1                        2   \n",
       "1              MEDIC                              2                        2   \n",
       "2             ENGINE                              4                        2   \n",
       "3              TRUCK                              2                     10.0   \n",
       "4             ENGINE                              1                        4   \n",
       "...              ...                            ...                      ...   \n",
       "7557           MEDIC                              2                        9   \n",
       "7558           MEDIC                              2                        8   \n",
       "7559         PRIVATE                              1                        5   \n",
       "7560         PRIVATE                              2                        8   \n",
       "7561  RESCUE CAPTAIN                              3                        3   \n",
       "\n",
       "     supervisor_district          neighbourhood            rowid  \\\n",
       "0                      6                Mission  220230253-SCRT6   \n",
       "1                      6             Tenderloin     220230206-63   \n",
       "2                      6             Tenderloin    220230288-E03   \n",
       "3                     10  Bayview Hunters Point    220230165-T17   \n",
       "4                      6             Tenderloin    220230127-E03   \n",
       "...                  ...                    ...              ...   \n",
       "7557                  11          Outer Mission     220320063-76   \n",
       "7558                   7              Lakeshore     220320084-58   \n",
       "7559                   5       Western Addition  220320127-AM120   \n",
       "7560                   4        Sunset/Parkside  220320152-KM104   \n",
       "7561                   6        South of Market    220320134-RC1   \n",
       "\n",
       "                                          case_location  \\\n",
       "0     {'type': 'Point', 'coordinates': [-122.4190886...   \n",
       "1     {'type': 'Point', 'coordinates': [-122.4173655...   \n",
       "2     {'type': 'Point', 'coordinates': [-122.4162597...   \n",
       "3     {'type': 'Point', 'coordinates': [-122.3982982...   \n",
       "4     {'type': 'Point', 'coordinates': [-122.4172576...   \n",
       "...                                                 ...   \n",
       "7557  {'type': 'Point', 'coordinates': [-122.4491688...   \n",
       "7558  {'type': 'Point', 'coordinates': [-122.4788651...   \n",
       "7559  {'type': 'Point', 'coordinates': [-122.4408636...   \n",
       "7560  {'type': 'Point', 'coordinates': [-122.4976191...   \n",
       "7561  {'type': 'Point', 'coordinates': [-122.4059313...   \n",
       "\n",
       "               transport_dttm            hospital_dttm  \n",
       "0                         NaN                      NaN  \n",
       "1     2022-01-23T02:16:10.000  2022-01-23T02:26:22.000  \n",
       "2                         NaN                      NaN  \n",
       "3                         NaN                      NaN  \n",
       "4                         NaN                      NaN  \n",
       "...                       ...                      ...  \n",
       "7557  2022-02-01T01:21:52.000  2022-02-01T01:41:49.000  \n",
       "7558  2022-02-01T01:48:18.000  2022-02-01T02:24:51.000  \n",
       "7559                      NaN                      NaN  \n",
       "7560                      NaN                      NaN  \n",
       "7561                      NaN                      NaN  \n",
       "\n",
       "[7562 rows x 34 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfs_data=cfs_data.rename(columns={\"call_type\":\"incident\",\"neighborhoods_analysis_boundaries\" : \"neighbourhood\" })\n",
    "cfs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfs_data=cfs_data.dropna()\n",
    "cfs_data= cfs_data.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>unit_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>Tenderloin</td>\n",
       "      <td>PRIVATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4012</th>\n",
       "      <td>Golden Gate Park</td>\n",
       "      <td>MEDIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6883</th>\n",
       "      <td>Lone Mountain/USF</td>\n",
       "      <td>MEDIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2894</th>\n",
       "      <td>Bayview Hunters Point</td>\n",
       "      <td>MEDIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>South of Market</td>\n",
       "      <td>MEDIC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              neighbourhood unit_type\n",
       "675              Tenderloin   PRIVATE\n",
       "4012       Golden Gate Park     MEDIC\n",
       "6883      Lone Mountain/USF     MEDIC\n",
       "2894  Bayview Hunters Point     MEDIC\n",
       "1661        South of Market     MEDIC"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cfs_small=cfs_data[['incident','neighbourhood','unit_type']].sample(5)\n",
    "cfs_small=cfs_data[['neighbourhood','unit_type']].sample(5)\n",
    "cfs_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TapasTokenizer.from_pretrained(\"google/tapas-base-finetuned-tabfact\", drop_rows_to_fit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>unit_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>Tenderloin</td>\n",
       "      <td>PRIVATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4012</th>\n",
       "      <td>Golden Gate Park</td>\n",
       "      <td>MEDIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6883</th>\n",
       "      <td>Lone Mountain/USF</td>\n",
       "      <td>MEDIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2894</th>\n",
       "      <td>Bayview Hunters Point</td>\n",
       "      <td>MEDIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>South of Market</td>\n",
       "      <td>MEDIC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              neighbourhood unit_type\n",
       "675              Tenderloin   PRIVATE\n",
       "4012       Golden Gate Park     MEDIC\n",
       "6883      Lone Mountain/USF     MEDIC\n",
       "2894  Bayview Hunters Point     MEDIC\n",
       "1661        South of Market     MEDIC"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.DataFrame.from_dict(cfs_small)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "iloc cannot enlarge its target object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-f2dc0464c94f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/models/tapas/tokenization_tapas.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, table, queries, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_batched\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m             return self.batch_encode_plus(\n\u001b[0m\u001b[1;32m    604\u001b[0m                 \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m                 \u001b[0mqueries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/models/tapas/tokenization_tapas.py\u001b[0m in \u001b[0;36mbatch_encode_plus\u001b[0;34m(self, table, queries, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    719\u001b[0m             )\n\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         return self._batch_encode_plus(\n\u001b[0m\u001b[1;32m    722\u001b[0m             \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mqueries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/models/tapas/tokenization_tapas.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[0;34m(self, table, queries, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0mqueries_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m         batch_outputs = self._batch_prepare_for_model(\n\u001b[0m\u001b[1;32m    789\u001b[0m             \u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/models/tapas/tokenization_tapas.py\u001b[0m in \u001b[0;36m_batch_prepare_for_model\u001b[0;34m(self, raw_table, raw_queries, tokenized_table, queries_tokens, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, prepend_batch_axis, **kwargs)\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_queries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueries_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_coordinates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m             \u001b[0mraw_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_coords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_txt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m             outputs = self.prepare_for_model(\n\u001b[0m\u001b[1;32m    844\u001b[0m                 \u001b[0mraw_table\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0mraw_query\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/models/tapas/tokenization_tapas.py\u001b[0m in \u001b[0;36mprepare_for_model\u001b[0;34m(self, raw_table, raw_query, tokenized_table, query_tokens, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, prepend_batch_axis, **kwargs)\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;31m# FIRST: parse both the table and question in terms of numeric values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m         \u001b[0mraw_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_numeric_table_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m         \u001b[0mraw_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_numeric_values_to_question\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/models/tapas/tokenization_tapas.py\u001b[0m in \u001b[0;36madd_numeric_table_values\u001b[0;34m(table, min_consolidation_fraction, debug_info)\u001b[0m\n\u001b[1;32m   2765\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2766\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcol_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2767\u001b[0;31m             \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2769\u001b[0m     \u001b[0;31m# Third, add numeric_value attributes to these Cell objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0miloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iloc\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_has_valid_setitem_indexer\u001b[0;34m(self, indexer)\u001b[0m\n\u001b[1;32m   1399\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iloc cannot enlarge its target object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1402\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iloc cannot enlarge its target object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: iloc cannot enlarge its target object"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(table=table, queries=queries,padding=True, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\"What neighbourhoods are incidents in?\", \"Which neighbourhood is the CHIEF unit type in?\", \"What neighourhoods are the medics in?\"]\n",
    "\n",
    "\n",
    "\n",
    "inputs = tokenizer(table=table, queries=queries, padding='max_length', return_tensors=\"pt\")\n",
    "logits = compute_prediction_sequence(model, inputs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_answer_coordinates, = tokenizer.convert_logits_to_predictions(inputs, logits.cpu().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handy helper function in case inference on Pandas dataframe\n",
    "answers = []\n",
    "for coordinates in predicted_answer_coordinates:\n",
    "  if len(coordinates) == 1:\n",
    "    # only a single cell:\n",
    "    answers.append(table.iat[coordinates[0]])\n",
    "  else:\n",
    "    # multiple cells\n",
    "    cell_values = []\n",
    "    for coordinate in coordinates:\n",
    "      cell_values.append(table.iat[coordinate])\n",
    "    answers.append(\", \".join(cell_values))\n",
    "\n",
    "display(table)\n",
    "print(\"\")\n",
    "for query, answer in zip(queries, answers):\n",
    "  print(query)\n",
    "  print(\"Predicted answer: \" + answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Fine-tuning TapasForQuestionAnswering on SQA.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "3bad5ab136084c2e92b55153828a403f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c95dd6249784fe6a2a466737e5f5866": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "45fdca8a04f94b43b021c590181e8a48": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "695d0c44ebbe4a55a17c735645c26c82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_be6159a5be0945629a517297df1170b8",
       "IPY_MODEL_b889ffa28a1949e9ac46e205ee582688"
      ],
      "layout": "IPY_MODEL_7e3cd6c49143436bad3d84be7ca2cf79"
     }
    },
    "768723f1af4c4bf497064a9796567382": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c6aadbda246d47fcad9660c2f57926a0",
       "IPY_MODEL_cd910003940b498e94db9746091e4c3c"
      ],
      "layout": "IPY_MODEL_82bfe5d88c5546358de33952e42221a3"
     }
    },
    "7e3cd6c49143436bad3d84be7ca2cf79": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "82bfe5d88c5546358de33952e42221a3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a11bc2e0d34543d1bb0ab708e0cc1a67": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b889ffa28a1949e9ac46e205ee582688": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3bad5ab136084c2e92b55153828a403f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_45fdca8a04f94b43b021c590181e8a48",
      "value": " 443M/443M [00:06&lt;00:00, 66.0MB/s]"
     }
    },
    "be6159a5be0945629a517297df1170b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf9382ee988f4787a88340d3b2af95f3",
      "max": 442768791,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3c95dd6249784fe6a2a466737e5f5866",
      "value": 442768791
     }
    },
    "c6aadbda246d47fcad9660c2f57926a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d59737fa0a424a90ba02110e4cf1b639",
      "max": 1432,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a11bc2e0d34543d1bb0ab708e0cc1a67",
      "value": 1432
     }
    },
    "cd910003940b498e94db9746091e4c3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f6fef10b29f74c458d05c2cbda46bf4a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_d534c2ebdbb144efa59500fcadf6e118",
      "value": " 1.43k/1.43k [00:00&lt;00:00, 4.46kB/s]"
     }
    },
    "cf9382ee988f4787a88340d3b2af95f3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d534c2ebdbb144efa59500fcadf6e118": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d59737fa0a424a90ba02110e4cf1b639": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6fef10b29f74c458d05c2cbda46bf4a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
